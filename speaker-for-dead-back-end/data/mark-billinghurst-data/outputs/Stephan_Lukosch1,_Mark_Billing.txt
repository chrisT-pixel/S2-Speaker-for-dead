Stephan_Lukosch1,_Mark_Billing
Stephan Lukosch1, Mark Billinghurst2, Leila Alem3 &amp; Kiyoshi Kiyokawa4 1Faculty of Technology Policy and Management, Delft University of Technology, Delft , The Netherlands (Email: s.g.lukosch@tudelft.nl); 2School of Information Technology and Mathematical Sciences, University of South Australia, Adelaide , Australia (Email: mark.billinghurst@unisa.edu.au); 3Thoughtworks, Sydney , Australia (Email: leila.alem@thoughtworks.com); 4Osaka University, Suita , Japan (Email: kiyo@ime.cmc.osakau.ac.jp) 
Abstract. Augmented Reality (AR) is a technology that allows users to view and interact in real time with virtual images seamlessly superimposed over the real world. AR systems can be used to create unique collaborative experiences. For example, colocated users can see shared 3D virtual objects that they interact with, or a user can annotate the live video view of a remote worker, enabling them to collaborate at a distance. The overall goal is to augment the facetoface collaborative experience, or to enable remote people to feel that they are virtually colocated. In this special issue on collaboration in augmented reality, we begin with the visions of science fiction authors of future technologies that might significantly improve collaboration, then introduce research articles which describe progress towards these visions, finally we outline a research agenda discussing the work still to be done. 
In the Otherland saga, Tad Williams (1996, 1998, 1999, 2001) describes a future world with a widespread availability of fullimmersion Virtual Reality (VR) installations which allow people to access an online world, called simply the Net. Within the Net, a group of people aim to achieve immortality. In his novel Rainbows End (Vinge 2007) Vernor Vinge describes how the main character, Robert Gu, is slowly recovering from Alzheimers disease and adapts to a changed world in which almost every object is networked and the use of Augmented Reality (AR) is normal. Humans experience AR by wearing smart clothes and contact lenses that can overlay the physical environment with computer graphics. In this future world, AR technology is used for various purposes, such as largescale commercial gaming, supporting maintenance workers with blueprints of machines or buildings, communication with virtual avatars, and medical diagnosis. 
AR allow users to see the real world, with virtual objects superimposed upon or composited with their real environment (Azuma 1997). Here the virtual objects are computer graphics that exist in essence or effect, but not formally or actually (Milgram and Kishino 1994). AR systems are not limited to use of headmounted 
devices (HMD), but AR technology mainly has to combine real and virtual objects, to be interactive in realtime, and to register virtual objects within the real 3D environment (Azuma 1997). 
Williams and Vinge forecast a vision for the future that current research on collaboration in AR is addressing. Several years from now, technology will provide an infrastructure for physical and virtual connectivity just as described in Rainbows End. Everyday objects will be connected and be able to provide and exchange information. Instead of only overlaying the physical environment with computer graphics, future AR systems will move closer to the ultimate display that Ivan Sutherland envisioned as Ba room within which the computer can control the existence of matter. A chair displayed in such a room would be good enough to sit in. Handcuffs displayed in such a room would be confining, and a bullet displayed in such a room would be fatal.^ (Sutherland 1965). Such a display would allow for holistic embodied experiences addressing all of the human senses, such as sound, smell, taste and touch, as envisioned in Otherland. Early science fiction motion pictures, e.g., Star Wars (Lucas 1977), used holistic experiences to support the interaction and collaboration of geographically distributed persons.When this fiction comes true, the use of and interaction within AR environments will be as natural as in the real world. 
First steps towards a combined vision of Williams and Vinge have already been taken. There has been research on introducing smell (Kim et al. 2011) and touch (Samur 2012) into movie theaters and television. However, one of the most difficult aspects to reproduce is realistic interaction with other (real or virtual) humans. Olson and Olson (2000, 2014) analysed the efforts of geographically distributed teams to use technology to create sense of being in one place and work together. They came to the conclusion that distance matters and that current technology is not mature enough to enable virtual copresence, and even future technology will struggle to enable this. In their opinion, providing awareness among coworkers and enabling coreference as well as spatial referencing will remain a challenge. Gaver (1991) stresses the importance of supporting awareness information to help actors shifting fromworking alone to working together. 
Considering current groupware technology, this forecast is still correct. Complex problem solving still requires a team of experts to physically meet and interact with each other. The identification of the problem and the creation of a shared understanding are major challenges for efficiently solving a problem (Piirainen et al. 2012). Unfortunately, due to experts availability, critical timing issues or accessibility of a location, it is not always possible to bring a team together to handle a complex situation. While in the novel Rainbows End, such situations are supported with AR technology, current AR experiences are not there yet. 
This special issue includes four articles that focus on remote collaboration using different types of AR systems. They advance the state of the art and provide insights about how AR can be used for remote guidance, what are critical design factors, and what is the impact on awareness. Most importantly, they show how close current AR 
systems are to the future Science Fiction visions described above. After reviewing the state of the art of collaboration using AR systems, this introduction builds upon the articles in this special issue and outlines a research agenda for future work on remote collaboration supported by AR systems. 
Several studies have explored the effectiveness of using AR for complex tasks. For individual users, Baird and Barfield (1999) showed that AR can improve the effectiveness of assembly tasks. Similarly, Tang et al. (2003) showed that the use of AR improves performance and reduces mental effort in assembly tasks. Bauer et al. (1999) show that in a distributed setting a remote user can effectively guide and direct a local users activities using an AR telepointer. Wang and Dunston (2011) showed that AR systems can improve performance time and mental effort in collaborative design tasks. Dong et al. (2013) found that AR facilitates communication and discussion of engineering processes. Alem and Li (2011) showed that AR can improve the satisfaction with remote collaboration on physical tasks. Recent results on using AR for collaboration among crime scene investigators, indicates that it supports mutual understanding, leads to consensus and supports hypothesis testing (Poelman et al. 2012). 
There are several examples of using AR technology for supporting facetoface collaboration. The Transvision system (Rekimoto 1996) allows multiple users to share computergenerated graphics on a table. The Collaborative Web Space (Billinghurst and Kato 1999, 2002) allows users in the same location to collaboratively browse the web while seeing the real world and communicate naturally about the visited pages. The Studierstube system (Schmalstieg et al. 2002; Szalavri et al. 1998) targets presentations and education and allows users to walk around shared virtual 3D scientific data superimposed over the real world. EMMIE (Butz et al. 1999) uses AR to connect people and devices by visualizing crossdevice interactions, search, and privacy status during a meeting. VITA (Benko et al. 2004) supports multiple users in exploring scaled and fullsize representations of an archaeological dig. More recent systems considered the use of AR in dynamic emergency response tasks (Nilsson et al. 2009) or within a board game, in which users play social games with physical game pieces using a handheld on a tabletop (Huynh et al. 2009). Similarly, ARVita (Dong et al. 2013) enables multiple users around a table wearing HMDs to observe and interact with dynamic visual simulations of engineering processes. Some of the key lessons learned from these systems are that users can interact with shared AR content as naturally as with physical objects, AR reduces separation between task space and communication space, and that AR enhances natural facetoface communication cues. 
Examples for AR systems that support remote collaboration can be found in Billinghurst and Kato (1999), Hllerer et al. (1999), Stafford et al. (2006), Minatani et al. (2007), Poelman et al. (2012), Datcu et al. (2014a), or Billinghurst and Thomas 
(2011). For example, WearCom (Billinghurst and Kato 1999) enables users to see remote collaborators as virtual avatars in real space. Hllerer et al. (1999) allow indoor AR users to visualize the locations and paths of outdoor AR users, and create shared annotations. Stafford et al. (2006) introduce a new interaction metaphor called Bgodlike interaction^ which supports multiscale interaction between outdoor wearable AR users and indoor users using a tabletop projector, and aims at improving sharing of situational and navigational information between remote users. Minatani et al. (2007) describe a system that enables two distributed users to a play a tabletop game in an AR conferencing scenario. Poelman et al. (2012) introduce and evaluate an AR system that allows remote experts to collaborate with local investigators on a crime scene investigation in order to secure evidence. Along the same line Datcu et al. (2014a), present a system that supports situational awareness of crossorganisational teams in the security domain. Some of the key lessons learned from these systems are that AR technology can reproduce some of the spatial cues used in facetoface collaboration that are normally lost in remote conferencing systems, AR can increase social presence compared to other technologies, and AR also allows remote collaborators to interact naturally in the local users real environment (Billinghurst and Thomas 2011). 
In addition to the above systems, collaborative AR has also been used in several industry scenarios such as product design, maintenance or factory planning. The ReMote system (Alem et al. 2011; Huang et al. 2013) is a remote assistance system that allows a remote expert to assist and guide in real time a local maintenance operator in a mine site. The remote expert uses their own hands (hand gestures over a live video of the workspace) as well as annotations on still images to explain how the repair /maintenance task needs to be performed. The MagicMeeting system (Regenbrecht et al. 2002) is a multiuser AR system that allows up to four colocated users to have a design zone review meeting. Fata Morgana (Klinker et al. 2002) supports five different scenarios for car designers where they can rotate a car, perform an overview evaluation, focus on details, discuss with colleagues, and compare designs. Roivis (Pentenrieder et al. 2007) is an AR application that supports factory design and planning between colocated users that share a view. DARCC (Hammad et al. 2009) is a distributed AR application that allows multiple users to simulate collaborative construction tasks, e.g., coordinating crane operations. Gauglitz et al. (2014) introduce a tabletbased system that incorporates a touch screen interface through which a remote user can navigate a physical environment and create worldaligned annotations for supporting maintenance. Oda et al. (2013) present a system for remote equipment maintenance. These systems show that collaborative AR technology could have significant impact in design and industrial applications. 
In summary, AR technology is becoming mature enough to support a variety of complex collaboration scenarios (Carmigniani et al. 2011; Piekarski and Thomas 2009). However, there are still a number of open issues that need further research. One major issue with regard to AR collaboration is in relation to the presence of 
remote users (Billinghurst and Thomas 2011). Local users may feel remote controlled by the remote experts, while the experts may feel that they miss something when not physically being present at the scene (Poelman et al. 2012). It is unknown if the proven concepts of awareness support from traditional desktop collaboration situations (Schmmer and Lukosch 2007) can be transferred to AR interaction spaces, or whether completely new approaches are necessary. Billinghurst and Thomas (2011) also point out that further research on how users can interact within collaborative AR systems is necessary. For example, investigating whether bare hand interaction or interaction with a physical object is more effective in AR (Datcu et al. 2015). 
Recent research has shown that virtual colocation is in fact possible. Poelman et al. (2012) allows experts to spatially collaborate with others at any other place in the world without traveling and thereby creating the experience of being virtually colocated. In the field of crime scene investigation, a remote expert guides and collaborates with a colleague in a crime scene to collect evidence. In this setting, the remote colleague wears a headmounted display with a camera and shares the local view with the remote colleague, while both can annotate what they see with virtual objects. Datcu et al. (2014a, b) use AR to establish virtual colocation and improve the telepresence of a remote colleague for police investigations, fire fighting or reconnaissance. In 3DReMoTe (Huang and Alem 2013; Huang et al. 2013), the expert sees a real time a reconstruction &amp; display of a remote workspace via a HMD. The hands of the expert are captured in 3D and colocated in the 3D remote workspace, allowing the expert to assist in spatial tasks. These projects show that AR can enable virtual colocation and allow experts at a distance to interact with local users to perform collaborative tasks. 
The articles in this special issue present results that continue the line of research as outlined in the previous section. They provide novel insights on remote collaboration in augmented reality and bring us closer towards the combined vision of Tad Williams and Vernor Vinge. 
In the first article, Pavel Gurevich, Joel Lanir and Benjamin Cohen describe the design and implementation of TeleAdvisor, a projectionbased AR system for remote collaboration. Using a small projector and two cameras mounted on top of a teleoperated robotic arm at the local users side, TeleAdvisor allows a remote user to guide the local user in physical tasks that need to be performed. They show that their solution supports flexibility of movements, representational gestures, mixed perspectives, and control of both worker and helper. Based on their findings, they discuss the general implications for design of future AR remote collaboration systems. 
Next, Matt Adcock and Chris Gunn present a similar approach for providing remote guidance to a local worker. Their system allows a remote expert to see the workplace from a local workers point of view. The remote expert can then draw AR 
annotations to guide the local worker. The annotations are projected onto the real world and can be made to stick to one physical location. Compared to the previous article, however, Adcock and Gunn do not use a robotic arm, but developed a system that can be worn by the local worker. In their user study, they evaluate the user appreciation of a wearable system compared to a fixed AR system, as well as user appreciation of sticky annotations (e.g., digital annotations that stick to physical objects) compared to digital annotations that move with users movement. Their evaluation suggests that users prefer the sticky annotations, however, they also show that user performance is better when using a fixed setup compared to a wearable setup. 
The two previous articles describe solutions to provide remote guidance to a local user. In remote guidance scenarios, the remote user often views the local scene from the point of view of the local user. In the third paper, Matthew Tait and Mark Billinghurst discuss the effect of view independence for the remote user in such a scenario. For that purpose, they present a collaborative AR system that allows a remote user to assist a local user in an object placement task. Unlike most other systems, their AR system allows the remote user to have an independent view into the shared task space. In a user study on remote assistance for a twodimensional object placement task, they show that increased view independence leads to faster task completion and a decrease in time spent on communication during the task. 
The final paper of the special issue by Stephan Lukosch, Heide Lukosch, Drago Datcu and Marina Cidota discusses the use of AR for improving situational awareness of teams in the security domain. Lukosch et al. present a collaborative AR system that allows a local and remote user to jointly annotate a local scene using AR. The remote user can provide additional information on the spot. The presented system has been evaluated in two rounds with experts from different operational units in the security domain. The evaluation shows that the AR system can successfully support information exchange in teams operating in the security domain and that it can improve the team situational awareness. The evaluation also showed that the participating experts especially valued the guidance of the remote expert, as well as the possibility to better exchange information among teams from different organization in the security domain. 
The four articles in this special issue focus on remote collaboration scenarios and the possibility to provide remote assistance, guidance or additional information to local users. All the articles also highlight the necessity for future research. Gurevich et al. stress that is it necessary to further research the support for remote users and how virtual content is visualized. Adcock and Gunn point out that further research is necessary to understand which tasks are suitable for remote guidance and how the local site is presented to the remote user with regard to issues around presence and efficiency of support. Tait and Billinghurst conclude that further research is needed to 
improve the usability of the 3D user interface used by the remote expert. Lukosch et al. argue that further research is necessary to understand the impact of AR on team situational awareness. Looking further, they consider user scenarios beyond the remote guidance scenario and ask the question to what extent can AR be used in training situations and how realistic such environments have to be in order to achieve good training outcomes.. 
Future research on collaboration in AR will thus have to focus on exploring situations that are suitable for virtual colocation. Further experiments need to be conducted to explore how remote users can interact with the local users and how their presence and awareness can be improved. Typically, a remote user perceives the local site via a standard desktop user interface. It is an open question whether more immersive 3D visualisations for remote users by, e.g., using a HMD, will impact the interaction, Presence and awareness in virtual colocation scenarios. 
Dubois et al. (1999) discuss the evolution of interaction paradigms from graphical user interfaces to tangible user interfaces, and Augmented Reality. For future collaborative AR systems, there is a need to research which interaction paradigms will be most effective. Starting from proven concepts for 3D user interfaces (Bowman et al. 2004) and remote collaboration (Schmmer and Lukosch 2007), research will have to go beyond current AR systems and create effective 3D user interfaces for groups of multiple local as well as remote users. To enhance the virtual colocation experience and to facilitate the remote guiding task, more research is needed to explore how to further enhance the communication bandwidth between users. Current research efforts around multimodal interactions combining gestures, audio and annotations (Huang and Alem 2013), around using physical objects as interaction means (Datcu et al. 2015), or around how to provide remote users with a full control of their view, where they are able to zoom in and out, change their point of view as they see fit (as pointed out by Tait and Billinghurst in this special issue) are early steps in this direction. 
To enhance the perception of presence of remote users, the effect of stimulating other senses (e.g., olfactory) on the perception of presence and situational awareness needs to be researched. First steps in this direction, have been done by (Narumi et al. 2011) who created an AR system that changes the perceived taste of a cookie by overlaying visual and olfactory information onto a real cookie. 
Finally, more intuitive interaction possibilities among virtual and real objects need to be developed. Schraffenberger and van der Heide (2013) explored how real objects can affect virtual objects and vice versa. Using several examples, Schraffenberger and van der Heide (2013) argue that virtual and real objects can simulate influences that exist between real entities. Going even further, they give examples on how virtual and real objects can influence each other in new and imaginary ways. Based on these insights, future research needs to explore how distributed users can be empowered to interact with the environment and each other. 
In summary, to create an AR system that supports remote collaboration and establishes virtual colocation, research on suitable scenarios, interaction paradigms, Presence and situational awareness needs to be conducted. This special issue on collaboration in Augmented Reality can be seen as a steppingstone toward the future vision that is outlined in the novels from Williams and Vinge. It is hoped that this special issue will encourage other researchers to become part of the fascinating research and help shape this future. 
Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. 
Alem, Leila, and Jane Li (2011). A Study of Gestures in a VideoMediated Collaborative Assembly Task. Advances in HumanComputer Interaction, vol. 2011, Article ID 987830, 7 pages. 
Azuma, Ronald T. (1997). A Survey of Augmented Reality. In Presence: Teleoperators and Virtual Environments, vol. 6, no. 4, pp. 355385. 
Azuma, Ronald T., Yohan Baillot, Reinhold Behringer, Steven Feiner, Simon Julier, and Blair MacIntyre (2001). Recent advances in augmented reality. Computer Graphics and Applications, vol. 21, no. 6, pp. 3447. 
Baird, K. M., and Woodrow Barfield (1999). Evaluating the effectiveness of augmented reality displays for a manual assembly task. Virtual Reality, vol. 4, no. 4, pp. 250259. 
Bauer, Martin, Gerd Kortuem, and Zary Segall (1999). BWhere Are You Pointing At?^ A Study of Remote Collaboration in a Wearable Videoconference System. In Proceedings of the 3rd IEEE International Symposium on Wearable Computers, San Francisco, CA, USA, 1819 October 1999, Washington, DC, USA: IEEE Computer Society, pp. 151158. 
Benko, Hrvoje, Edward W. Ishak, and Steven Feiner (2004). Collaborative Mixed Reality Visualization of an Archaeological Excavation. In Proceedings of the 3rd IEEE/ACM International Symposium on Mixed and Augmented Reality, Arlington, VA, USA, 25 November 2004, Washington, DC, USA: IEEE Computer Society, pp. 132140. 
Billinghurst, Mark and Hirokazu Kato (1999). Collaborative Mixed Reality. In Proceedings of the First International Symposium on Mixed Reality (ISMR99). Mixed Reality Merging Real and Virtual Worlds, Yokohama, Japan, 1921 March 1999, Berlin, Germany: Springer Verlag, pp. 261 284. 
Billinghurst, Mark and Hirokazu Kato (2002). Collaborative augmented reality. Communications of the ACM, vol. 45, no. 7, pp. 6470. 
Billinghurst, Mark and Bruce H. Thomas (2011). Mobile Collaborative Augmented Reality. In W. Huang and L. Alem (Ed.), Recent Trends of Mobile Collaborative Augmented Reality Systems, Dordrecht etc.: Springer, pp. 119. 
Bowman, Doug A., Ernst Kruijff, Joseph J. LaViola Jr, and Ivan Poupyrev (2004). 3D User Interfaces: Theory and Practice. Boston etc.: AddisonWesley. 
Butz, Andreas, Tobias Hllerer, Steven Feiner, Blair MacIntyre, and Clifford Beshers (1999). Enveloping users and computers in a collaborative 3D augmented reality. In Proceedings of the 2nd 
IEEE and ACM International Workshop on Augmented Reality (IWAR99), San Francisco, CA, USA, 2021 October 1999, pp. 3544. 
Carmigniani, Julie, Borko Furht, Marco Anisetti, Paolo Ceravolo, Ernesto Damiani, and Misa Ivkovic (2011). Augmented reality technologies, systems and applications. Multimedia Tools and Applications, vol. 51, no. 1, pp. 341377. 
Datcu, Dragos, Marina Cidota, Heide Lukosch, and Stephan Lukosch (2014a). On the Usability of Augmented Reality for Information Exchange in Teams from the Security Domain. In IEEE Joint Intelligence and Security Informatics Conference (JISIC), The Hague, Netherlands, 2426 September 2014, Washington, DC, USA: IEEE Computer Society, pp. 160167. 
Datcu, Dragos, Marina Cidota, Heide Lukosch, and Stephan Lukosch (2014b). [Poster] Using Augmented Reality to Support Information Exchange of Teams in the Security Domain. In IEEE International Symposium on Mixed and Augmented Reality (ISMAR), Munich, Germany, 1012 September 2014, Washington, DC, USA: IEEE Computer Society, pp. 263264. 
Datcu, Dragos, Stephan Lukosch, and Frances Brazier (2015). On the Usability and Effectiveness of Different Interaction Types in Augmented Reality. International Journal of HumanComputer Interaction, vol. 31, no. 3, pp. 193209. 
Dong, Suyang, Amir H. Behzadan, Feng Chen, and Vineet R. Kamat (2013). Collaborative Visualization of Engineering Processes Using Tabletop Augmented Reality. Advances in Engineering Software, vol. 55, pp. 4555. 
Dubois, Emmanuel, Laurence Nigay, Jocelyne Troccaz, Olivier Chavanon, and Lionel Carrat (1999). Classification Space for Augmented Surgery, an Augmented Reality Case Study. In A. Sasse &amp; C. Johnson (Eds.), Proceedings of Interact99, Edinburgh, UK, 30 August3 September 1999, IOS Press, pp. 353359. 
Gauglitz, Steffen, Benjamin Nuernberger, Matthew Turk, and Tobias Hllerer (2014a). In Touch with the Remote World: Remote Collaboration with Augmented Reality Drawings and Virtual Navigation. In Proceedings of the 20th ACM Symposium on Virtual Reality Software and Technology, Edinburgh, UK, November 1113 2014, New York, NY, USA: ACM, pp. 197205. 
Gaver, William W. (1991). Sound Support for Collaboration. In Proceedings of the Second Conference on European Conference on ComputerSupported Cooperative Work, Kluwer Academic Publishers, Norwell, MA, USA, pp. 293308. 
Hammad, Amin, Hui Wang, and Sudhir P. Mudur (2009). Distributed Augmented Reality for Visualizing Collaborative Construction Tasks. Journal of Computing in Civil Engineering, vol. 23, no. 6, pp. 418427. 
Hllerer, Tobias, Steven Feiner, Tachio Terauchi, Gus Rashid, and Drexel Hallaway (1999). Exploring MARS: developing indoor and outdoor user interfaces to a mobile augmented reality system. Computers &amp; Graphics, vol. 23, no. 6, pp. 779 785. 
Huang, Weidong and Leila Alem (2013). Gesturing in the Air: Supporting Full Mobility in Remote Collaboration on Physical Tasks. Journal of Universal Computer Science (J.UCS), vol. 19, no. 8, pp. 11581174. 
Huang, Weidong, Leila Alem, and Franco Tecchia (2013). HandsIn3D: Supporting Remote Guidance with Immersive Virtual Environments. In P. Kotz, G. Marsden, G. Lindgaard, J. Wesson, &amp; M. Winckler (Eds.), HumanComputer InteractionINTERACT 2013, Cape Town, South Africa, September 26 2013, Heidelberg New York Dordrecht London: Springer, pp. 7077. 
Huynh, DuyNguyen Ta, Karthik Raveendran, Yan Xu, Kimberly Spreen, and Blair MacIntyre (2009). Art of defense: a collaborative handheld augmented reality board game. In Proceedings of the 2009 ACM SIGGRAPH Symposium on Video Games, New Orleans, LA, USA, 37 August 2009, New York, NY, USA: ACM, pp. 135142. 
Kim, Hyunsu, Jongjin Park, Kunbae Noh, Calvin J. Gardner, Seong Deok Kong, Jongmin Kim, and Sungho Jin (2011). An XY Addressable Matrix OdorReleasing System Using an OnOff Switchable Device. Angewandte Chemie, vol. 123, no. 30, pp. 69036907. 
Klinker, Gudrun, Allen H. Dutoit, Martin Bauer, Johannes Bayer, Vinko Novak, and Dietmar Matzke (2002). Fata Morgana A Presentation System for Product Design. In Proceedings of the 1st International Symposium on Mixed and Augmented Reality, Darmstadt, Germany, 30 September1 October 2002, Washington, DC, USA: IEEE Computer Society, pp. 110. 
Lucas, George (1977). Star Wars [Motion Picture]. United States: 20th Century Fox. Milgram, Paul and Fumio Kishino (1994). A taxonomy of mixed reality visual displays. IEICE 
Transactions on Information Systems, vol. E77D, no. 12, pp. 13211329. Minatani, Shinya, Itaru Kitahara, Yoshinari Kameda, and Yuichi Ohta (2007). FacetoFace Tabletop 
Remote Collaboration in Mixed Reality. In Proceedings of the 6th IEEE and ACM International Symposium on Mixed and Augmented Reality, Nara, Japan, 1316 November 2007, Washington, DC, USA: IEEE Computer Society, pp. 14. 
Narumi, Takuji, Shinya Nishizaka, Takashi Kajinami, Tomohiro Tanikawa, and Michitaka Hirose (2011). Meta Cookie+: An IllusionBased Gustatory Display. In R. Shumaker (Ed.), Virtual and Mixed RealityNew Trends, Springer Berlin Heidelberg, pp. 260269. 
Nilsson, Susanna, Bjrn Johansson, and Arne Jnsson (2009). Using AR to support crossorganisational collaboration in dynamic tasks. In 8th IEEE International Symposium on Mixed and Augmented Reality, Orlando, FL, USA, 1922 October 2009, Washington, DC: IEEE Computer Society, pp. 312. 
Oda, Ohan, Mengu Sukan, Steven Feiner, and Barbara Tversky (2013). Poster: 3D referencing for remote task assistance in augmented reality. In IEEE Symposium on 3D User Interfaces (3DUI 2013), Orlando, FL, USA, 1617 March 2013, Washington, DC, USA: IEEE Computer Society, pp. 179180. 
Olson, Gary M. and Judith S. Olson (2000). Distance Matters. HumanComputer Interaction, vol. 15, nos. 23, pp. 139178. 
Olson, Judith S. and Gray M. Olson (2014). How to Make Distance Work Work. Interactions, vol. 21, no. 2, pp. 2835. 
Pentenrieder, Katharina, Christian Bade, Fabian Doil, Peter Meier (2007). Augmented Realitybased factory planningan application tailored to industrial needs. In Proceedings of the 6th IEEE and ACM International Symposium on Mixed and Augmented Reality, Nara, Japan, 1316 November 2007, Washington, DC, USA: IEEE Computer Society, pp. 3142. 
Piekarski, Wayne and Bruce H. Thomas (2009). ThroughWalls Collaboration. IEEE Pervasive Computing, vol. 8, no. 3, pp. 4249. 
Piirainen, Kalle, Gwendolyn Kolfschoten, and Stephan Lukosch (2012). The Joint Struggle of Complex Engineering: A Study of the Challenges of Collaborative Design. International Journal of Information Technology &amp; Decision Making (IJITDM), vol. 11, no. 6, pp. 139. 
Poelman, Ronald, Oytun Akman, Stephan Lukosch, and Pieter Jonker (2012). As if Being There: Mediated Reality for Crime Scene Investigation. In CSCW12: Proceedings of the 2012 ACM conference on Computer Supported Cooperative Work, San Francisco, CA, USA, 27 February 2 March 2016, New York, NY, USA: ACM, pp. 12671276. 
Regenbrecht, Holger T., Michael T. Wagner, and Gregory Baratoff (2002). MagicMeeting: A Collaborative Tangible Augmented Reality System. Virtual Reality, vol. 6, no. 3, pp. 151166. 
Rekimoto, Jun (1996). Transvision: a handheld augmented reality system for collaborative design. In Proceeding of Virtual Systems and Multimedia (VSSM96), Gifu, Japan, September 1820, 1996. 
Samur, Evren (2012). State of the Art. In Performance Metrics for Haptic Interfaces. London, UK: Springer, pp. 926. 
Schmalstieg, Dieter, Anton Fuhrmann, Gerd Hesina, Zsolt Szalavri, L. Miguel Encarnacao, Michael Gervautz, and Werner Purgathofer (2002). The Studierstube Augmented Reality Project. Presence: Teleoperators and Virtual Environments, vol. 11, no. 1, pp. 3354. 
Schraffenberger, Hanna and Edwin van der Heide (2013). From coexistence to interaction: influences between the virtual and the real in augmented reality. In Proceedings of the 19th International Symposium on Electronic Art, ISEA2013, Sidney, Australia, 716 June 2013. 
Schmmer, Till and Stephan Lukosch (2007). Patterns for ComputerMediated Interaction. Chichester, West Sussex, England: John Wiley &amp; Sons, Ltd. 
Stafford, Aaron, Wayne Piekarski, Bruce H. Thomas. (2006). Implementation of godlike interaction techniques for supporting collaboration between outdoor AR and indoor tabletop users. In Proceedings of the 5th IEEE and ACM International Symposium on Mixed and Augmented Reality, Santa Barbara, CA, USA, 2225 October 2006, Washington, DC, USA: IEEE Computer Society, pp. 165172. 
Sutherland, Ivan E. (1965). The Ultimate Display. In Proceedings of the Congress of the Internation Federation of Information Processing (IFIP), New York, USA, May 2429, 1965, Washington, USA: Spartan Books, vol. 2, pp. 506508. 
Szalavri, Zsolt, Dieter Schmalstieg, Anton Fuhrmann, Michael Gervautz (1998). BStudierstube^: An Environment for collaboration in augmented reality. Virtual Reality, vol. 3, no. 1, pp. 3748. 
Tang, Arthur, Charles Owen, Frank Biocca, and Weimin Mou (2003). Comparative effectiveness of augmented reality in object assembly. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, Fort Lauderdale, FL, USA, 510 April 2003, New York, NY, USA: ACM, pp. 7380. 
Vinge, Vernor (2007). Rainbows End. New York City, USA: Tor Books. Wang, Xiangyu and Phillip S. Dunston (2011). Comparative Effectiveness of Mixed RealityBased 
Virtual Environments in Collaborative Design. IEEE Transactions on Systems, Man, and Cybernetics, Part C: Applications and Reviews, vol. 41, no. 3, pp. 284296. 
Williams, Tad (1996). OtherlandCity of Golden Shadow. London, UK: Legend Books. Williams, Tad (1998). OtherlandRiver of Blue Fire. London, UK: Legend Books. Williams, Tad (1999). OtherlandMountain of Black Glass. London, UK: Legend Books. Williams, Tad (2001). OtherlandSea of Silver Light. London, UK: Legend Books. 
