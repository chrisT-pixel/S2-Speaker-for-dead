Introduction In the Arts Center of Christchurch New Zealand there is an empty dusty basement room. This room isn't much different from other basement rooms, however visitors are treated to a very unique experience. Upon entering, they hear a voice telling then to come closer into the darkness. When they do, a lifesized virtual image of an old man appears floating in front of them. The man turns, looks at them and tells what it was like working in this dark space over a hundred year ago. He is Ernest Rutherford, New Zealand's Nobelprize winning physicist, and the room is where he performed his first research as an undergraduate at the University of Canterbury. Through the use of advanced technology an empty space is turned into a very rich educational experience. 
The ability to overlay computer graphics onto the real world is commonly called Augmented Reality (AR). Unlike immersive Virtual Reality, AR interfaces allow users to see the real world at the same time as virtual imagery attached to real locations and objects. In an AR interface, the user views the world through a handheld or head mounted display (HMD) that is either seethrough or overlays graphics on video of the surrounding environment. AR interfaces enhance the real world experience, unlike other computer interfaces that draw users away from the real world and onto the screen. 
Single user Augmented Reality interfaces have been developed for computeraided instruction [Feiner 93], manufacturing [Caudell 92] and medical visualization [Bajura 92]. These applications have shown that Augmented Reality interfaces can enable a person to interact with the real world in ways never before possible. For example, Bajura, et al, have developed a medical interface that overlays virtual ultrasound images onto a patient's body, allowing doctors to have "XRay" vision in a needle biopsy task [Bajura 92] (figure 1). In Feiner's work, users can see virtual annotations appearing over a laser printer, showing them how to repair the machine [Feiner 93] (figure 2). In both of these cases the user can move around the threedimensional virtual image and view it from any vantage point, just like a real object.
Augmented Reality can also be used to enhance collaborative tasks. A good example of this is the StudierStube project of Schmalsteig, et al [Schmalsteig 96]. They use seethrough head mounted displays to allow users to collaboratively view 3D models of scientific data superimposed on the real world (figure 3). They report users finding the interface very intuitive and conducive to real world collaboration, because the groupware support can be mostly left to social protocols. The AR2 Hockey work of Ohshima, et al, [Ohshima 98] is very similar. In this case two users wear seethrough head mounted displays to play an AR version of the classic game of air hockey. As they move a real mallet over a real table, they send a virtual puck towards each other's goals. 
AR technology has matured to the point where it can be applied to a much wider range of application domains, and education is an area where this technology could be especially valuable. The educational experience offered by Augmented Reality is different for a number of reasons, including: Support of seamless interaction between real and virtual environments The use of a tangible interface metaphor for object manipulation The ability to transition smoothly between reality and virtuality 
Seamless Interaction In a classroom setting, students work together better if they are focused on a common workspace. Yet this is difficult to achieve in computerbased education. Children working on separate computers, even if they are side by side, do not perform as well as they would if they were huddled around a single machine [Inkpen 97]. Indeed, researchers have found that when students are assigned to individual computers, they will spontaneously cluster around machines in pairs and trios [Watson 91, Strommen 93]. 
Even when seated in front of the same computer, group communication patterns are different. When students work at a table, the space between them is used for sharing communication cues such as gaze, gesture, and nonverbal behaviors. If the people are talking about objects on the table, then the taskspace is a subset of the communication space. The collaborators can see each other and the shared communication cues at the same time as the objects they are discussing. However, when users are collaborating in front of a desktop screen, they are often sitting sideby
side and their attention is focused on the screen space. In this case, the task space is part of the screen space and is separate from the interpersonal communication space. 
In contrast, in an Augmented Reality interface students can be seated around a table and see each other at the same time as a virtual heart floating in their midst. This results in conversational behavior that is more similar to natural facetoface collaboration than to screen based collaboration [Kiyokawa 2002]. 
Tangible Interface Metaphor In educational settings physical objects or props are commonly used to convey meaning. As Gav points out, in a collaborative setting speakers use the resources of the physical world to establish a socially shared meaning [Gav 97]. Physical objects support collaboration both by their appearance, the physical affordances they have, their use as semantic representations, their spatial relationships, and their ability to help focus attention. 
In Augmented Reality there is an intimate relationship between virtual and physical objects. The physical objects can be enhanced in ways not normally possible such as by providing dynamic information overlay, private and public data display, context sensitive visual appearance, and physically based interactions. AR applications based on a tangible interface metaphor use physical objects to manipulate virtual information in an intuitive manner. In this way people with no computer background can still have a rich interactive experience. For example, in the Shared Space interface users could manipulate threedimensional virtual objects simply by moving real cards that the virtual models appeared attached to [Poupyrev 2000]. There was no mouse or keyboard in sight. This property enables even very young children to have a rich educational experience. 
Transitional Interfaces Milgram points out that computer interfaces can be placed on a continuum according to how much of the user's world is generated by the computer [Milgram 94] (figure 4). Moving from left to right the amount of virtual imagery increases and the connection with reality weakens. AR technology can be used to transition users smoothly along this continuum, as shown by the MagicBook work [Billinghurst 2001]. 
Young children often fantasize about being swallowed up into the pages of a fairy tale and becoming part of the story. The MagicBook makes this fantasy a reality by using a normal book as the main interface object. People can turn the pages of the book, look at the pictures, and read the text without any additional technology (figure 5a). However, if they look at the pages through a handheld Augmented Reality display, they see threedimensional virtual models appearing out of the pages (figure 5b). The models appear attached to the real page, so users can see the AR scene from any perspective simply by moving themselves or the book. The
models can be any size and are also animated, so the AR view is an enhanced version of a traditional threedimensional "popup" book. Users can change the virtual models simply by turning the book pages. When they see a scene they particularly like, they can fly into the page and experience the story as an immersive virtual environment (figure 5c). In the VR view, they are free to move about the scene at will and interact with the characters in the story. Thus, users can experience the full RealityVirtuality continuum. 
As can be seen the MagicBook interface supports new forms of educational experience. No longer are textbooks static sources of information. Through the use of Augmented Reality the printed page can become means to move students to animated interactive virtual environments. 
Conclusions Although Augmented Reality technology is not new, it's potential in education is just beginning to be explored. Unlike other computing technologies, AR interfaces offer seamless interaction between the real and virtual worlds, a tangible interface metaphor and a means for transitioning between real and virtual worlds. Educators should work with researchers in the field to explore how these characteristics can best be applied in a school environment. 
Bajura, M., Fuchs, H., Ohbuchi, R. (1992) "Merging Virtual Objects with the Real World: Seeing Ultrasound Imagery Within the Patient." In Proceedings of SIGGRAPH '92, New York: ACM Press, pp. 203210. 
Caudell, T.P., and Mizell, D.W. (1992)"Augmented Reality: an application of headsup display technology to manual manufacturing processes." In Proceedings of the TwentyFifth Hawaii International Conference on Systems Science, Kauai, Hawaii, 7th10th Jan. 1992, Vol. 2, pp. 659669. 
Feiner, S., MacIntyre, B., and Seligmann, D. (1993) "KnowledgeBased Augmented Reality." Communications of the ACM, Vol. 36(7), pp. 5362. 
Gav, G., Lentini, M. "Use of Communication Resources in a Networked Collaborative Design Environment." http://www.osu.edu/units/jcmc/IMG_JCMC/ResourceUse.html. 
Inkpen, K. (1997) Adapting the Human Computer Interface to Support Collaborative Learning Environments for Children. PhD Dissertation, Dept. of Computer Science, University of British Columbia, .
K. Kiyokawa, M. Billinghurst, S. Hayes, A. Gupta, Y. Sannohe, H. Kato. (2002) " Communication Behaviors of CoLocated Users in Collaborative AR Interfaces." In Proceedings of the IEEE and ACM International Symposium on Mixed and Augmented Reality (ISMAR 2002), 30 Sept.1 Oct., 2002, Darmstadt, Germany, IEEE Press, Los Alamitos, CA, pp. 139148. 
Milgram, P., Kishino, F. A, (1994) "Taxonomy of Mixed Reality Visual Displays." IECE Trans. on Information and Systems (Special Issue on Networked Reality), vol. E77D, no. 12, pp.13211329 . 
Ohshima, T., Satoh, K., Yamamoto, H. and Tamura, H.(1998) "AR2 Hockey: A Case Study of Collaborative Augmented Reality," Proc. IEEE VRAIS '98, pp.268275 . 
Poupyrev, I., Billighurst, M. Kato, H., May, R.(2000) "Integrating Real and Virtual Worlds in Shared Space." In Proceedings of the 5th International Symposium on Artificial Life and Robotics (AROB 5th'00), Oita, Japan, 2628 January 2000, Vol. 1, pp. 2225. 
Schmalsteig, D., Fuhrmann, A., Szalavari, Z., Gervautz, M., (1996) "StudierstubeAn Environment for Collaboration in Augmented Reality." In CVE '96 Workshop Proceedings, 1920th September 1996, Nottingham, Great Britain. 
Strommen, E.F. (1993) "Does yours eat leaves?" Cooperative learning in an educational software task." Journal of Computing in Childhood Education, 4(1), 4556. 
Watson, J. (1991)" Cooperative learning and computers: One way to address student differences." The Computing Teacher, 18(4), pp. 915. 
Mark Billinghurst is a researcher developing innovative computer interfaces that explore how virtual and real worlds can be merged to enhance facetoface and remote collaboration. Director of the Human Interface Technology Laboratory (New Zealand) (HIT Lab NZ) and a research scientist at the HIT Lab (US), he has produced over 80 technical publications and his work has been demonstrated at a wide variety of conferences. 
He is active in several research areas including Augmented and Virtual Reality, wearable computing and conversational computer interfaces. He has previously worked at ATR Research Labs in Japan, British Telecom and the MIT Media Laboratory. 
