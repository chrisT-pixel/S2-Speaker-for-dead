1National University of Singapore, Singapore; 2Human Interface Technologies Laboratory, University of Washington, Seattle, WA, USA; 3Hiroshima City University, Japan 
Abstract: This paper presents a novel computer entertainment system which recaptures human touch and physical interaction with the realworld environment as essential elements of the game play, whilst also maintaining the exciting fantasy features of traditional computer entertainment. Our system called TouchSpace is an embodied (ubiquitous, tangible, and social) computing based Mixed Reality (MR) game space which regains the physical and social aspects of traditional game play. In this novel game space, the realworld environment is an essential and intrinsic game element, and the humans physical context influences the game play. It also provides the full spectrum of game interaction experience ranging from the real physical environment (human to human and human to physical world interaction), to augmented reality, to the virtual environment. It allows tangible interactions between players and virtual objects, and collaborations between players in different levels of reality. Thus, the system reinvigorates computer entertainment systems with social humantohuman and humantophysical touch interactions. 
Keywords: Embodied computing; Game space; Mixed reality; Social computing; Tangible interaction; Ubiquitous computing 
Humans, as social creatures find physical interaction, touch, and humantohuman presence essential for the enjoyment of life [1]. Computer entertainment also can provide humans with enjoyment, by allowing virtual fantasy and imaginative play activity to be carried out. However, present computer entertainment focuses the users attention mainly on computer screens or 2D/3D virtual environments, rather than interactions between humans. Physical and social interaction is constrained, and natural interactions such as gestures, body language and movement, gaze, and physical awareness are lost [2]. 
The concepts of ubiquitous and tangible computing propose that the computer is embedded in our environment, in objects, and in the background. Similarly, social computing proposes that the realtime and realspace activities of humans as social beings are placed at primary importance. Thus, in this research the theories of ubiquitous, tangible, and social computing, together with mixed reality, is used 
Ownership and Copyright # SpringerVerlag London Ltd 2002 Personal and Ubiquitous Computing (2002) 6:430442 
Adrian David Cheok, Xubo Yang, Zhou Zhi Ying, Mark Billinghurst, and Hirokazu Kato, "TouchSpace: Mixed Reality Game Space Based on Ubiquitous, Tangible, and Social Computing," Personal and Ubiquitous Computing, Vol. 6 , No. 56, pp. 430442, SpringerVerlag, London, UK, 2002.
1961, MIT student Steve Russell created Spacewar (see Fig. 1), which can be considered as the first interactive graphical computer game, on a Digital PDP1 mainframe computer [4]. In that game, an oscilloscope displayed the graphics, and people could only play the game on a device that took up the floor space of a house. After several decades of development, what prevails in the game market nowadays are video games and pc games featured with amazing 3D graphics and 3D sound on much smaller devices. 
However, almost all computer games limit the players in front of a 2D screen through which 3D graphic projections are displayed. Players have very little physical body movement, and a much smaller physical area of game space comparing with when they play a precomputer type game. Thus, the 2D screen becomes an abstractive and indirect obstacle between the player and the game context. 
Furthermore, with the support of internet, we no longer need to physically come together with friends and family to play games that involve other people than ourselves. Interaction is with other users on screen character or icon, rather than in a real tangible manner. Thus, physical and social interaction is limited, and natural interactions such as gestures, body language and movement, gaze, and physical awareness are lost. Paradoxically, although the computer games with networks can allow people to communicate with each other efficiently, in some situations it has created a barrier between humans, because humans have a psychologically need for social and physical interaction [5]. 
Recently, Virtual Reality (VR) has given rise to fully immersive computer games where there is some physical movement. Through means of 3D stereo display, datagloves and other sensor mechanisms, players can fully immerse themselves into a computergenerated virtual world. One example of a VR game is CAVE Quake [6]. However, while VR games merge the players mind and awareness into the virtual world, they separate the virtual world from the physical world. The physical movement is usually limited to hand and head pose movement to control ones virtual avatar. The player is thus almost disconnected from the physical world where she actually exists, so that the game context also excludes the information from the physical world. In addition, facetoface humanhuman interaction is replaced by communication via virtual avatars. In such a case, there is little chance for using natural human physical interaction abilities. 
As far as the interaction level between players and game context is concerned, we can see that interactions in precomputer games consisted of two elements: human to physical world interaction and human to human interaction. In a computer game, the human to real physical world interaction has been reduced and been replaced by an indirect human to virtual world interaction, and the human to human interaction has been changed from a facetoface manner to an indirect and nontangible mediated manner. 
Nevertheless, we know computer games are very popular because they allow virtual fantasy and imaginative play activity to be carried out [7]. Thus, people enjoy playing present computer games, and it is a very large entertainment industry [8]. Thus, it is interesting to find an approach to retain the exciting elements brought by computer games, as well as simultaneously regaining the natural physical world interactions embedded in precomputer games. 
The approach to increase physical interaction and human to human communication in computer games has been followed recently by research labs, as well as commercial systems: 
First, commercial arcade games have recently seen a growing trend of games that require human physical movement as part of the interaction. For example, dancing games such as Dance Dance Revolution and ParaParaParadise (made by Konami, Japan) are based on 
TouchSpace: Mixed Reality Game Space Based on Ubiquitous, Tangible, and Social ComputingTouchSpace: Mixed Reality Game Space Based on Ubiquitous, Tangible, and Social Computing
the players dancing in time with a musical dance tune and moving graphical objects (Fig. 1). These games allow physical movement interaction (for example dancing together) between the players. However, present systems still focus the attention of the users to a screen, and the physical movement is constrained to one spot. 
Secondly, various research projects related to computer entertainment have also emphasized some aspects of physical movement and human to human interaction: 
AR2 Hockey [9] is a system which allows two users to hit a virtual puck on a real table where they can see each other through a HMD, as shown in Fig. 3 
AquaGuantlet [10] is a multiplayer game where players fight with space invaders coming from the virtual world through some eggshape objects into the physical game space. The Magic Book [11] uses a book metaphor to demonstrate the seamless transitions between augmented reality and virtual reality. 
searchers at the PLAY and NOKIA research studios, implements a multiplayer mobile game on PDAs with proximity sensing technology to incorporate a players contextual information (such as the physical colocation of players and objects in the world) into the game context as important elements of the game mechanics. The Pirates! game also emphasizes the social nonmediated interaction between the players by taking the colocation between multiple players as one of the intrinsic elements of the game. 
The E3 project [2] examines the essential elements of free play, such as spontaneity, physical cues, awareness information and multiuser social interaction. The E3 project proposes to take a humancentered approach to support these elements in colocated CSCP (Computer Supported Cooperative Play), by providing support for multiple people playing together in the physical world, tangible interaction with physical space, fullbody movements, and physical activities [13]. 
Although these research systems have had a major impact in the research field, some of the improvements that can be made to these research systems are as follows: 
AR2 Hockey and AquaGuantlet are AR games which have no transition between AR and VR, and the players are still focused on digital objects rather than exploring the physical environment together with other cooperators. However, it would be advantageous to provide a full spectrum of the game experience in physical reality, AR, and VR spaces through a seamless transition interface and to have players explore a physical game space together, and use the physical world information to interact with the game space. 
Pirates! uses the contextual information in a physical space to interact with a 2D game on a small PDA screen. Thus, the players have to mentally map between the small 2D game context and the 3D physical space. However, it would be advantageous to directly deploy the physical space information in a 3D mixed reality space with tangible interfaces, and have the game context directly associated with the physical game space without an indirect mental mapping process being required. In essence it would be of benefit to have virtual objects that are tangible and become naturally embedded in the real environment. 
humantophysical interaction and humantohuman interaction. In addition to the concern on these physical game elements, it would be advantageous to maintain the exciting fantasy features of traditional computer entertainment, by providing seamless augmented reality objects in the environment and transitions into a virtual world. 
The Magic Book uses a book metaphor, so that the collaborations are carried out in a smallscale, closeup configuration. In this system, body movement and other largescale contextual information is not of concern. However, it would be advantageous to explore a MR space with a roomscale size where movement about this space is essential (as it is in the realworld). Thus a primary concern is the contextual information in a largescale space, and how to merge the humantophysical interaction, humantohuman interaction and humantovirtual interaction in a largescale configuration. 
Hence, to improve on previous game systems focusing on physical and social interaction, in this research a novel approach is developed that employs the theory of embodied computing together with mixed reality to create a novel computer game space. Embodied computing [14] is a next generation computing paradigm which involves the elements of ubiquitous computing [15], tangible computing [16], as well as social computing [17]. It places computation and interaction throughout and with the environment, as well as incorporating the sociological organization of interactive behavior. 
Ubiquitous computing provides advantages for creating a novel game space as it provides technology that is designed to be embedded in the natural human environment which responds to peoples needs and actions in a contextual manner [18]. Tangible computing directly links the digital world and the physical world and allows the computational world to engage and employ our physical and tactile skills which we are intimately familiar with. It also provides a seamless method of allowing natural physical interaction and collaboration between people [19]. Social computing allows advantages for the novel game space by incorporating the integration of peoples interaction with technology that does not follow formal theoretical abstracts or procedures but are improvised naturally in realtime. 
visions mentioned above have a central strand that deals with the role of context in interaction. The role of context is seen in the spatial and temporal context found in ubiquitous computing, the physical context found in tangible computing, and the social, cultural, organizational, and interactional context found in social computing. Thus, all are mutually dependant on the concept of embodiment, or a presence and interaction in the world in terms of realtime and realspace. Hence, they define the concept of embodied computing [14]. 
For example, ubiquitous and tangible computing is based upon the idea of the computer being embedded in our environment, in objects, and in the background. Thus, the interaction is embodied in the physical environment, rather than on abstract representations on a computer system. Similarly social computing places the realtime and realspace activities of humans as social beings, or embodied actions, at primary importance. Embodied computing ties all these ideas together, as a single research vision. Furthermore, embodied computing foresees that the future of humancomputer interaction will lie in an interface to computing that appears throughout our physical space and time. Thus, humans as physical beings now actually become situated inside the computational world. 
Mixed Reality (MR) covers the full RealityVirtuality spectrum proposed in Milgram and Kishino [20], involving the spectrum of physical reality, augmented reality and virtual reality. Thus, combining mixed reality with embodied computing allows us to create a rich physical environment, where digital 3D objects are embedded and are manipulated directly in a collaborative manner with natural interactions in the physical world. In the most common mixed reality paradigm, the user wears a HeadMounted Display (HMD) through which she views the real world, either directly, or via a video camera attached to the front of the display. Virtual objects are then superimposed on the real world. The minimal requirements for this are that the position of the camera must be determined relative to the whole scene (or an object therein). The transformation matrix between the scene and camera coordinates can then be used to generate the correct view of the virtual object. To achieve this at interactive frame rates is a considerable technical challenge. 
TouchSpace: Mixed Reality Game Space Based on Ubiquitous, Tangible, and Social ComputingTouchSpace: Mixed Reality Game Space Based on Ubiquitous, Tangible, and Social Computing
In TouchSpace, the game is situated and carried out in the physical world with a roomsize space, which allows humantohuman and humantophysical touch interaction. In this section, we will introduce the details of the game which has three stages, in which two players should collaboratively finish some tasks, and then rescue a princess in a castle controlled by a witch. 
We now outline the story of the game play. In this game space, a princess is captured by a witch and is trapped in the witchs castle that is located in a mysterious land. To play the game, firstly the two players need to find two map pieces of the mysterious land and other necessary treasures. Secondly, they should fly above the land and look for the castle, after then, they need to fight and defeat the witch. Finally, they enter the castle to find the princess, and thus they complete the game mission. Thus, the game consists of three main game stages which are detailed below: 
This is an augmented reality experience stage, which allows the users to experience tangible interaction and physical world contextual awareness. In this stage, two players need to collect enough treasures and avoid dangers in the roomsize game area. 
The floor is divided into a lattice, and there are some tangible objects (real boxes) in the space, as seen in Fig. 4. Intersense IS900 inertialacoustic hybrid tracking devices are mounted on the ceiling. While players walk around in the game space, their head and hand position are tracked by the tracking devices. We use the 
users location information to interact with the system, so that the user can actually interact with the game context using their bodily movement in a roomsize area, which incorporates the social context into the game experience. 
For example, in the first game stage, the players should walk around in the physical game space to collect treasures and avoid dangers. If the player steps into a grid which conceals a virtual mine, the mine may blow up, and decrease their score. Note that this entails that humans physical context directly influences the game play, and the players bodily movement is an essential and intrinsic feature of the game play. Furthermore, the computation features of the game play (location of mines and treasures) are embedded in the physical space in a ubiquitous manner. Figure 4 shows two players are exploring the physical game space collaboratively. They are opening the boxes to collect treasures. 
Each player wears a HMD (Cyvisor DH4400VP) on the head and holds a wand in their hands. The HMD is attached with small video camera (FireFly 1394 digital camera or a 2.4 Ghz frequency wireless camera) to support videosee through augmented reality. The video camera is also used for tracking markers attached to the tangible objects in the game space. There is a marker in each box, and when the user opens one box, the position of the box is tracked by the camera through the calculation of the markers position using the ARToolkit [21]. Then a virtual object can be displayed in the box. Figure 5 shows three snapshots of what a player sees when opening a box, which in this case contains a virtual airplane. 
hidden by the box, so that the virtual object disappears just as a real object would if it really were in a box. In this way, the ordinary physical box becomes an intuitive tangible interface to interact with virtual objects. Furthermore, these virtual objects are distributed through the physical space in a physical manner. 
The player holds a wand in their hand as a tool for exploring the game space. The wand can be used in various ways in a different game context. In the first stage, the wand is used to shown as a virtual board to display some hint information to the players, for example, to distinguish the explored area and the unexplored area, or to warn potential dangers in neighboring grids. Figure 6 shows the content of the virtual pad during the physical space exploration. The white color indicates unexplored area. 
After the players obtain a high enough score by collecting the necessary treasures, they enter the second game stage, in which they should find a castle and fight a witch. 
This is an augmented reality experience stage, which stresses the seamless interaction with virtual objects and virtual figures with body movement, and the seamless transitions between AR world and the VR world. In this stage, a virtual land is embedded seamlessly to the physical ground. The two players need to find the castle in it. They will hold a small virtual 3d window functioning as a seethrough lens through which they can see part of a virtual land which appears on the ground. Each player 
TouchSpace: Mixed Reality Game Space Based on Ubiquitous, Tangible, and Social ComputingTouchSpace: Mixed Reality Game Space Based on Ubiquitous, Tangible, and Social Computing
views their virtual 3D airplane flying above their wand. Thus once again, tangible interaction (the virtual plane is directly tied to the players wand), ubiquitous computing (the virtual land is embedded in the physical space), and social computing (the players explore the area together, and see each others body movements and gestures) are exemplified. 
Since they can only see the part of the virtual land corresponding to their current physical body location, they need to walk around in the roomsize area to be able to find the castle, thus increasing body movement and interaction. The three pictures in Fig. 7 shows the scrolling 3D landscape when the player is looking for the castle. A small virtual plane is attached to the wand as an avatar for the user, as if the user is exploring the game space by manipulating the plane. 
Note that, during this stage, the users can hear a synthesized 3D sound of their coplayers airplane (the airplane propeller sound). In this way, the users can always be aware of the location of their coplayers with the 3D sound even without seeing them. 
Once the players find the castle, they will see the witch flying out of the castle through the small magic window which they hold, and the witch will jump into the physical environment where they are located (thus showing a seamless transition between the virtual and physical world). The witch will fly above the players and throw fireballs to the players. The players need to physically move their body to avoid being hit by the fireballs, and at the same time shoot at the witch. Furthermore, they directly see each other, as well as the virtual objects. Thus, physical interaction and social interactive game play is felt by the users. Figure 8 shows the two players in a battle with a virtual witch hovering around them. 
shown in Fig. 10(b). Thus the user in the physical space can keep a constant social interaction and viewpoint with the user who has entered the VR environment. 
Furthermore, the player who has already entered the VR mode can also keep in constant interaction with the person who is in the physical world. Player one will see a plane flying above in the sky according to player twos real physical movement in the AR mode, which in turn corresponds to the actual location of the players hand (wand) in the physical game space, as illustrated in Fig. 10(c). In this way, players are always aware of the other players location, even if they are in different realities. Hence a social interactive feeling can be maintained even between different realities. 
This is a VR experience stage, featured with fully immersive VR navigation (Fig. 11). In this stage, the players will see they are in the virtual castle and they need to navigate in to find the princess. In this case, the players can see each other as avatars in the VR environment. 
After the user is fully immersed in the virtual lands, she can hear the 3D sound of the princesss voice calling help, help . . ., which helps her to localize the relative position of the princess and thus guides her toward the princess. A game rule is set that the princess cannot be rescued unless both coplayers are standing in front of the princess. Therefore, the user needs to find her coplayer and invite the coplayer to walk together toward the princess. 
Fig. 10. Collaboration in different spaces. (a) Player two can see player one transiting to VR through her plane diving into her wand; (b) after player one has entered the VR world, player two can see player ones VR avatar corresponding to her actual position in the VR world; (c) player one, who is experiencing egocentric VR can see player two moving in the AR space. This corresponds to his real physical movement of his wand. 
TouchSpace: Mixed Reality Game Space Based on Ubiquitous, Tangible, and Social ComputingTouchSpace: Mixed Reality Game Space Based on Ubiquitous, Tangible, and Social Computing
the coplayers airplane in the sky. When the coplayer is flying down to the virtual land, the user 
To experimentally verify the effectiveness of the developed game, we have conducted a formal user study for the Touch Space system. In the experimental user studies, our main focus was to examine the users reaction and feedback to the main features of the embodied mixed reality system. This includes the physical and tangible interaction with the ubiquitous mixed reality environment, cooperation, and collaboration between players, user comparisons with other types of computer games, and the reactions of the users to wearing the HMD. 
Forty users were selected from volunteers from the National University of Singapore engineering departments first year students, and the users 
Players Mission Find treasures (e.g. map pieces) and avoid dangers (e.g. bomb) in the physical space 
Moving body to find the castle in the virtual land through a handheld small virtual seethrough window, see part of the virtual land scrolling in the window when player moves body; 
Technical Features Ubiquitous contextual awareness and body movement interaction: physical location and colocation are essential game elements; 
Ubiquitous contextual awareness and body movement interaction: physical location and colocation are essential game elements; 
were paid SGD $8 for one hour test time. Among them were 13 girls and 27 boys. Their average age was 21.1 years old. The users were asked to selfrate their familiarity with computer games of any sort from a scale of 0 (none) to 10 (extremely familiar). The average score of their familiarity with computer games was 5.13 out of 10. We spent four days to study those 40 users, or about ten users per day. As mentioned above, we designed a questionnaire with focus on physical interaction, social interaction, and the evaluation of the HMD. For the tests, the users were asked to fill in the questionnaire after using the system and completing certain tasks. The users were asked to perform following tasks in sequence: 
. Find the Castle: In the AR stage where they could see part of the virtual world through the small window attached on their wand, the users were requested to find the castle and princess by walking around in the game space and looking at the virtual world through this small window. 
. Collaborate to create fireball and battle the witch: In the AR stage where the witch is flying around in the space, the users were asked to battle with the witch. 
. Find the princess together with the other players: Next, the user was asked to transit from the AR stage into the VR stage by pressing a button on the wand and then together with the coplayer find and rescue the witch. 
The first part of the questionnaire contained feedback about the physical interaction aspects of the game from the test users. The first question asked if they felt more entertained with moving, rather than with playing a computer game in front of a screen. The question asked was as follows: 
The results are show in Fig. 12. It appears that this test group affirmatively feels that the motion in the game system does provide more entertainment that nonmotion in computer games. 
A second question asked about the users feeling of entertainment with tangible mixed reality graphics appearing in the physical world. The question was stated as follows: 
The results are shown in Fig. 13, where it appears that the users did feel having tangible mixed reality graphics added excitement to the game experience. 
The users were also asked to provide written answers to justify their scores. For the answers to the above two questions, the users who thought physical movement and tangible mixed reality were more entertaining gave reasons such as more realism, more interaction, and more involvement in the game than traditional computer games. Users wrote that they felt they became part of the game due to freedom of whole body movement. Some users said I feel that I am really part of the game. To summarize, most users reported a strong feeling of participation in the game. 
Although the user studies are small and not statistically large, these results provide some justification to the claim that the integration of traditional games physical interaction into computer games can make the computer game more entertaining than a computer game played in front of a screen. 
Also of equal importance is to note the negative comments of the test users. The users who didnt feel the system was more entertaining than conventional computer games attribute the reasons to the heavy HMD, a dizzy feeling, 
TouchSpace: Mixed Reality Game Space Based on Ubiquitous, Tangible, and Social ComputingTouchSpace: Mixed Reality Game Space Based on Ubiquitous, Tangible, and Social Computing
tiredness from the physical movement, and the simplicity of the game rules. This points to future improvements that would be required in mixed reality entertainment, in particular the hardware should be small, light and preferably wireless. Also the game play should be as sophisticated as conventional computer games. 
In the second part of the user survey, feedback on the social interaction aspects was obtained. A comparison question was asked as follows: 
From the results that are shown in Fig. 14, we can see that most users think the collaboration between coplayers is easier than or at least as easy as the networked multiplayer game. And the number of users who prefer our system is almost similar to the number of users who prefer the networked multiplayer game. 
The reasons given by the users who prefer the mixed reality system include the intuitive communication between coplayers by sound and visual effects, and the direct and fast interactions between coplayers as in a reallife experience. This shows that the integration of real life interaction elements into computer games can allow users to collaborate intuitively and easily. 
The users who prefer the networked multiplayer game gave reasons include: more used to it, the instant messaging system, more realistic graphics and more coplayers online. This clearly shows that although the idea of social computer interaction is placed at high importance in this research, more future work in improving graphics, interaction with more players, and more communication methods such as messaging must be added to work closer to the goal of a highly social system. We believe it is not too difficult to make improvements on 
Another interesting question was related to the ways the users felt was most important for a sense of social presence with the other users. The question asked to the users was as follows: 
The results are shown in Fig. 15, where it can be interestingly seen that all forms such as talk, visual cues, and sound seem important to the users. 
We also designed questions asking users to evaluate the HMD, especially asking about its influence on social interaction. The question asked to the users was: 
The results are shown in Fig. 16. The result shows more users feel the HMD helps the social interactions. Some of the reasons given were: can directly see the coplayer, allow the user to explore the coplayer from all directions, can move around physically, feel like I am physically in the game and can walk towards coplayers, can see and interact in specific directions. 
These results are surprising, as intuition would have us think that no users would prefer to have the HMD. However, upon further questioning it was found in general that the users gave these reasons because they were comparing with 
The factors that the users think HMD hinders social interaction include the heaviness of the HMD, limited field of view, cables on the HMD. These answers suggest us to make improvements on the design of the HMD to make it lighter, wireless, and with a wider field of view. 
Our goal is to explore future MR and wearable computing technologies involving new styles of applications. We envision a new type of game experience that has two main features: integrated ubiquitous contextawareness and sociality into the computer interaction context, which entails ubiquitous, tangible, and social computing (and thus directly applies the theory of embodied interaction); and a seamless merging of physical world, augmented world and virtual world exploration experience. 
The ubiquitous computing theory has put into practice in the domain of work, but much less work has been conducted in the domain of play. Similarly, mixed reality technology has been investigated as an ideal collaborative interface to addresses major issues in CSCW (Computer Supported Collaborative Work): seamlessness and enhancing reality [22], but little work has been conducted to apply mixed reality technology to CSCP. By integrating mixed reality with embodied computing elements, which stresses human to physical world interaction and human to human interaction, we have actually made one step toward a better CSCP vision a tangible and social computing based MR CSCP. 
With ubiquitous computing the digital information is embedded in the environment, in objects, and in the background of the play space. Through tangible computing, players will be able to collaboratively play on shared virtual models by manipulating or comanipulating tangible interfaces rather than using nontangible icons or menus. Through social computing, players can collaborate in a more natural, socially organized way with other collaborators in the mixed reality game space. Furthermore, the realtime and realspace activities of the players as social beings are placed at primary importance. Thus, the real
world environment is an essential and intrinsic game element and the humans physical context influences the game play. 
Furthermore, by providing seamless transition between physical world and virtual world, the players can enjoy both tangible physical game experience and fantasy virtual game experience. 
Our visions on the new game experience and the new type of CSCP will bring great challenges and many open issues for the research and development such as: 
. How to incorporate the tangible interface with the MR space to enhance humantovirtual world interaction? 
. How to apply social computing ideas in the MR space to enhance humantovirtual world interaction? 
Furthermore, we aim that in the future, with the development of the wearable computing technologies, this embodied interaction MR space experience will be able to be carried out in a much largerscale space, and embedded into our everyday life physical environment. The future of the development will be a large MR collaboration space with wearable, networked sites. For example we could have football field sized games (for example we play a combination ball and shootup game over a football field sized space), or city wide adventure mixed reality entertainment (for example a spy adventure that takes place over a city). 
2. Mandryk RL, Inkpen KM. Supporting free play in ubiquitous computer games. Workshop on Designing Ubiquitous Computing Games, UbiComp 2001, Atlanta, GA 2001 
TouchSpace: Mixed Reality Game Space Based on Ubiquitous, Tangible, and Social ComputingTouchSpace: Mixed Reality Game Space Based on Ubiquitous, Tangible, and Social Computing
9. Ohshima T, Satoh K, Yamamoto H, Tamura H. AR2 Hockey system: A collaborative mixed reality system. Trans VRSJ 1998; 3(2): 5560 
10. Tamura H, Yamamoto H, Katayama A. Mixed reality: future deams seen at the border between real and virtual worlds. Computer Graph Applic 2001; 21(6): 6470 
11. Billinghurst M, Kato H, Poupyrev I. The MagicBook: Moving seamlessly between reality and virtuality IEEE Computer Graphics and Applications 2001, pp 24 
12. Bjork S, Falk J, Hansson R, Ljungstrand P. Pirates!Using the physical world as a game board. Interact 2001, IFIP TC.13 Conference on HumanComputer Interaction, Tokyo, Japan 2001 
13. Ishii H, Wisneski C, Orbanes J, Chun B, Paradiso J. PingPongPlus: Design of an athletictangible interface for computersupported cooperative play. CHI99 1999, pp 394401 
14. Dourish P. Where the Action Is: The Foundations of Embodied Interaction. MIT Press, Cambridge, MA 2001 
16. Ishii H, Ullmer B. Tangible bits: towards seamless interfaces between people, bits and atoms. Proceedings ACM Conf. Human Factors in Computing Systems, CHI97, Atlanta, GA 1997 
17. Suchman L. Plans and situated actions: The problem of humanmachine communication. Cambridge University Press, Cambridge, 1987 
18. Abowd GD, Mynatt ED. Charting past, present and future research in ubiquitous computing. ACM Trans ComputerHuman Interaction 2000; 7(1): 2958 
19. Billinghurst M, Kato H, Poupyrev I. Collaboration with tangible augmented reality interfaces. Proceedings HCII2001 2001; 1: 797803 
20. Milgram P, Kishino F. A taxonomy of mixed reality Vvsual displays. IECE Trans Information and Systems (Special Issue on Networked Reality) 1994; E77D(12): 13211329 
22. Billinghurst M, Kato H. Collaborative mixed reality. Proceedings First International Symposium on Mixed Reality (ISMR99). 1999, pp 261284 
Correspondence to: Professor A. Cheok, National University of Singapore, 10 Kent Ridge Crescent, Singapore 119260. Email: adriancheok@nus.edu.sg 
