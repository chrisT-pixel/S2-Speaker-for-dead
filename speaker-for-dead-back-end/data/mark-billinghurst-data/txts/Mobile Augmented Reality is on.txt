Mobile Augmented Reality is one of the fastest growing research areas in Augmented Reality, partially due to the emergence of smart phones that provide powerful and ubiquitous platforms for supporting mobile Augmented Reality. This special section contains seven papers on mobile AR, covering a range of topics from tracking, user studies, visualization, and collaborative applications. 
First developed over forty years ago, Augmented Reality (AR) is a technology that enables virtual content to be seamlessly merged with the real world. Although initially requiring custom hardware and software, in the last few years AR experiences have become widely available on mobile and handheld devices. One reason for this is the emergence of smart phones that combine fast CPUs with displays, cameras, graphics acceleration, compass, GPS sensors, and even gyroscopes. Now, people have a powerful AR hardware platform in their pockets. 
While mobile AR hardware has become commonplace, there is a need for more research on how to use this hardware to deliver a compelling mobile AR experience. Mobile AR is one of the fastest growing research areas in Augmented Reality and this special issue contains a set of papers that represent the leading edge of mobile AR research. 
We requested papers on topics such as tracking for mobile AR, interaction techniques, user evaluation, application case studies and mobile AR rendering and visualization techniques, among others. We received 23 submissions and after a long, rigorous review process, selected seven for inclusion in the special issue. We are grateful to all who submitted, the anonymous reviewers for their detailed evaluations, and to Joaquim Jorge for guiding us through the editorial process. The review process included one round of peer review followed by one or more rounds of review with the editors. Submissions that caused a conflict of interest with a guest editor were handled by an editor who did not have a conflict. For such submissions, the editors who had a conflict did not select reviewers, did not learn the identities of the assigned reviewers, and played no role in deciding paper acceptance. 
The seven accepted papers cover a wide range of topics in mobile AR. Taketomi et al. [5] describe a robust outdoor tracking method that uses two stages. In the initial offline stage, a landmark database is constructed from structure from motion data and laser range finder information. After this database is constructed, landmark tracking can be used in an online stage to provide widearea outdoor tracking for mobile AR applications. 
Gee et al. [1] adopt a different approach for tracking based on integrating a variety of different tracking technologies to create a system capable of operating in both indoor and outdoor environments. By combining realtime visual SLAM with global
positioning from both GPS and indoor ultrawideband technology, they were able to demonstrate successful creation and visualization of large numbers of AR annotations over a range of different locations. 
Wither et al. [7] propose and evaluate Indirect Augmented Reality, an alternate approach to mobile AR experiences that can provide convincing AR effects despite tracking imprecision in todays mobile smart phones in outdoor, uncontrolled environments. They implement prerecorded static panoramic images with precisely aligned augmentations and run a user study that suggests users find this alternate approach more compelling for some typical outdoor AR use cases. 
Langlotz et al. [3] present three techniques to improve the ability to accurately annotate points of interest in a panoramic image surrounding a mobile user, increasing the rate of accurate matches to 90% even under significant changes in illumination. Their system operates in real time on a mobile phone. 
Wientapper et al. [6] describe a tracking approach that fuses together several stateoftheart techniques for acquiring scene geometry, initializing tracking, and providing fast and accurate framebyframe tracking. The end result is a system than can provide accurate tracking through combining the estimates of the different techniques. 
Jo et al. [2] propose Aroundplot, which is a focuscontext visualization method to aid finding points of interest in an AR application on a mobile phone. They evaluate Aroundplot by comparing it against topdown 2D radar and 3D arrow visualization approaches. 
Morrison et al. [4] describe the collaborative use of videobased augmentations of paper maps using mobile phone AR. This approach investigates several new issues, including both the benefit of relating a navigational task to a physical (real) map that is augmented with personal information, and the benefit of using a physical map as a reference medium for collaborative work. 
All these works have valuable lessons for those interested in the field. We hope you enjoy the research in this special issue and that it will inspire you to explore mobile AR for yourself. The field is still young and there is a lot of exciting research that can still be done before the potential of mobile AR is fully explored.
[1] Gee Andrew, Webb Matthew, EscamillaAmbrosio Jorge, MayolCuevas Walterio, Calway Andrew. A topometric system for wide area augmented reality. Computers and Graphics 2011;35(4):85468. doi:10.1016/j.cag.2011.04.006. 
[2] Jo Hyungeun, Hwang Sungjae, Park Hyunwoo, Ryu Junghee. Aroundplot: focuscontext interface for offscreen objects in 3D environments. Computers and Graphics 2011;35(4):84153. doi:10.1016/j.cag.2011.04.005.
[3] Langlotz Tobias, Degendorfer Claus, Mulloni Alessandro, Schall Gerhard, Reitmayr Gerhard, Schmalstieg Dieter. Robust detection and tracking of annotations for outdoor augmented reality browsing. Computers and Graphics 2011;35(4):83140. doi:10.1016/j.cag.2011.04.004. 
[4] Morrison Ann, Mulloni Alessandro, Lemmela Saija, Oulasvirta Antti, Peltonen Peter, Jacucci Giulio, et al. Collaborative use of mobile augmented reality with paper maps. Computers and Graphics 2011;35(4):78999. doi:10.1016/ j.cag.2011.04.009. 
[5] Taketomi Takafumi, Sato Tomokazu, Yokoya Naokazu. Real time and accurate extrinsic camera parameter estimation using feature landmark database for augmented reality. Computers and Graphics 2011;35(4):76877. doi:10.1016/ j.cag.2011.04.007. 
[6] Wientapper Folker, Wuest Harald, Kuiper Arjan. Composing the feature map retrieval process for robust and readytouse monocular tracking. Computers and Graphics 2011;35(4):77888. doi:10.1016/j.cag.2011.04.008. 
[7] Wither Jason, Tsai YunTa, Azuma Ronald, Schmalstieg Dieter. Indirect augmented reality. Computers and Graphics 2011;35(4):81022. doi:10.1016/ j.cag.2011.04.010.
Ronald Azuma is a research leader at Nokia Research Center, where he leads a group developing new forms of compelling mobile media, interfaces and experiences, based on Augmented Reality and other technologies. Prior to joining Nokia, he worked at HRL Laboratories, conducting research in outdoor Augmented Reality, air traffic control visualization and Virtual Environments. He received a BS in Electrical Engineering and Computer Science from the University of California at Berkeley, and an MS and PhD in Computer Science from the University of North Carolina at Chapel Hill. Ronald is known for defining the field of Augmented Reality and helping to
papers. He is the current leader of the Steering Committee for the IEEE International Symposium on Mixed and Augmented Reality (ISMAR).
Mark Billinghurst is a researcher developing innovative computer interfaces that explore how virtual and real worlds can be merged. He is the Director of the HIT Lab New Zealand (HIT Lab NZ) at the University of Canterbury in New Zealand, and has produced over 200 technical publications and presented demonstrations and courses at a wide variety of conferences. He has a PhD from the University of Washington and conducts research in Augmented and Virtual Reality, wearable computing and mobile interfaces. He has previously worked at ATR Research Labs, British Telecom and the MIT Media Laboratory. One of his
2001 Discover award for best Entertainment application, and his AR Tennis project won the 2005 IMG award for best independent mobile game. In 2001 he cofounded ARToolworks, one of the oldest commercial AR companies. He currently serves on the Steering Committee for the IEEE International Symposium on Mixed and Augmented Reality (ISMAR).
Gudrun Klinker, a PhD, studied computer science (informatics) at the FriedrichAlexander Universitat Erlangen, Universitat Hamburg (Diplom) and CarnegieMellon University (PhD) in Pittsburgh, PA, USA, focusing on research topics in computer vision. In 1989, she joined the Cambridge Research laboratory of Digital Equipment Corporation in Boston, MA, working in the visualization group on the development of a reusable telecollaborative data exploration environment to analyze and visualize 3D and higherdimensional data in medical and industrial applications. Since 1995, she has been researching various aspects
first at the European Computerindustry Research Center, then at the Fraunhofer Institute for Computer Graphics, and since 2000 at the Technical University of Munich. At TU Munich, her research focus lies on developing approaches to ubiquitous Augmented Reality that lend themselves to realistic industrial applications. Prof. Klinker is one of the cofounders of the International Symposium of Augmented Reality (which later became ISMAR). She has served on numerous program committees such as VR, VRST, 3DUI, and UIST. She is author and coauthor of more than 100 reviewed scientific publications.
