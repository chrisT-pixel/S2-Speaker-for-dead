A lthough the Information Age has many upsides, one of its major downsides is information overload. Indeed, the amount of information easily pushes the limit of what people can manageand the consequences 
are sometimes deadly. ThreeMile Island and Chernobyl, two of the worst disasters in human history, were the result of information overload and mismanagement. 
But the same stress that produced these catastrophes is also driving research to seek a solution to humanitys information woes. As computers have shrunk from room size to palm size to fit better with their users lifestyle, so they have also moved from being passive accessories, such as laptops and personal digital assistants, to wearable appliances that form an integral part of our personal space. Wearable computers are always on and their wearers can always access them. This operational and interactional constancy is what sets them apart from more traditional forms of portable computing. 
Before wearable computers become as ubiquitous as wristwatches, however, many issues must be resolved. Current projects and industry efforts are attempting to define a new generation of wearables. Several conferences have already been held, in which attendees worldwide addressed the state of research and development, explored how wearable information appliances will let us manage information in new ways, and examined some of the obstacles to making wearables more widespread. The sidebar Current Work on Wearables describes how to locate proceedings from these meetings. Much of the work presented here comes from the workshop on wearable computers at the 1998 Virtual Reality Annual International Symposium (VRAIS 98) and the First 
wristmounted systems to bulky backpack computers. In most applications, a wearable is a combination of devicestypically a belt or backpack PC, headmounted display, wireless communications hardware, and some input device, such as a touch pad. This combination has dramatically improved user performance in such applications as aircraft maintenance, navigational assistance, and vehicle inspection. 
The elements of a wearable computer work to satisfy three goals. The first and most obvious is that they must be mobile: By its definition, a wearable must go where its wearer goes. The second goal is to augment reality, for example, by overlaying computergenerated images or audio on the real world. Unlike virtual reality, augmented reality seeks to enhance the real environment, not replace it. In the University of North Carolinas ultrasound project, for example, doctors performing a needle biopsy can look at the breast of a real patient and see the ultrasound of the tumor superimposed on it. 
The third goal is to provide context sensitivity. When a computer is worn it can be made aware of the users surroundings and state. Contextsensitive applications can then be developed to exploit the intimacy between human, computer, and environment. An example is the Touring Machine, developed by Steve Feiner of Columbia University, which uses a GPS (global positioning system) receiver and a headorientation sensor to track the wearer as he walks around looking at various buildings on campus.1 Those wear
The new generation of wearables may look very much like eyeglasses or even an ordinary jacket. But with this new convenience comes a host of challenges in redefining the bond between computer and user. 
ing the Touring Machine see, through their headmounted display, an overlay of department names and faculty members for each building. 
immersive headmounted display, video cameras, and 10 pounds of computer equipment.2 Such a combination, although tolerable (Steve Mann, its wearer, spent years continuously using it) was somewhat socially isolating. Current wearables, although far less obtrusive, are still awkward and noticeably 
apart from everyday wear. The new generation of wearables, however, are far more integrated with their wearers daily life. Figure 1 shows two examples. Figure 1a shows a headmounted display from MicroOptical that cannot be distinguished from prescription lenses. Although the display is almost invisible, it produces a 320 240 pixel image that covers a 10degree field of view and can be connected to a standard VGA output. 
Figure 1b shows a keyboard from MIT Media Lab that can be woven into clothing using conductive thread. Pressing the numbers on the keyboard causes digits to be sent to a connected computer, in the same way you would enter data using a traditional keyboard. The advantage is that the user need not carry a bulky, rigid input device. These advances point to a future generation of wearable computers indistinguishable from everyday clothing. Unfortunately, however, although the cloth may be washable, the attached circuit board isnt, so it will be some time before its wearers can treat it as ordinary clothing. 
As these examples show, the new generation of wearables will augment human intelligence in more dimensions than we see now. When you sit in front of a computer at a desk, you and the computer have a very weak (sometimes adversarial) personal relationship. The computer is very much apart from you. Laptops and PDAs, although more convenient, still exist obviously apart from their users. Wearable computers, in contrast, create an intimate humancomputer symbiosis in which respective strengths combine. 
Figure 1. Unobtrusive interfaces: (a) MicroOpticals headmounted display and (b) a cloth keyboard from MIT Media Lab that can be woven into its users clothing. These devices represent the first steps toward making wearable computers more pervasive. (Image of MicroOpticals headmounted display courtesy of Sam Ogden) 
wearable computers will be in every aspect of life; others see social acceptability as an obstacle to widespread use. Like most debates, the truth is probably somewhere in between. Initially, wearable computers will be used in vertical niche applications that require the user to be mobile, have handsfree access to information and computing power, and view human computer interaction as a secondary task. Applications are already appearing in military and medical emergency response, warehouse inventory, and vehicle maintenance. In these areas, wearables are demonstrating usefulness even though it has traditionally been dif
ficult to provide computer support. The defining characteristic of these domains is the need for technology transparency. Users must be able to leave their desktops and continue their daily tasks, while remaining connected to computing and communications resources. Xybernaut and ViA have targeted these areas as their initial markets. 
Wearable computers should then migrate to a larger consumer base, much as devices for mobile users (laptop computers and cell phones) have migrated to deskbound workers. Audible and Diamond Multimedia are already producing lowpower systems with flash memory that can play back hours of compressed speech or music. These systems show how content can be 
loaded onto a wearable computer without the inconvenience and expense of a physical medium. If this trend continues on its logical track, we should see versions of these machines with largecapacity storage and wireless networking capability invade the consumer electronics industry. Portable music, video, Web browsing, phone service, paging, email, and so on will be consolidated onto a wearable computer through additional peripherals and software, as desired. 
For the consumer, this reduces the costtofunctionality ratio of each new capability as well as providing a clear and inexpensive upgrade path for industry. Such a trend is already visible in the desktop market. 
One example of the power of this relationship is the enhanced ability to automatically gather and filter information. Wearers can use wirelessly networked wearable computers to access traditional Webbased search and retrieval tools, for example, to get timely data wherever they are. Because they sense context, wearable computers can use the wearers current state as an additional search term and retrieve only the most relevant data. 
The wearers then become the information gathering and filtering device and the wearable computer just the storage and retrieval tool. The Remembrance Agent software, developed by Brad Rhodes of the MIT Media Laboratory, is a good example of how a wearable computer can enhance human memory through intelligent filtering and proactive presentation.3 The Remembrance Agent runs continuously in the background, indexing everything a wearer stores on the computers hard disk. As the wearer enters text into his machine using a handheld device, the agent matches words to the index and retrieves other related documents. It can then make suggestions based on the most recent sentence, paragraph, or entire text input. By using additional contextual cues, such as the wearers location, the identity of people around him, and the current date and time, the agent can offer information the wearer might not have thought to ask for. Suppose, for example, the wearer is walking past the public library. The agent senses his location, filters it through existing data, finds that the wearer has overdue library books, and reminds him that the books need to go back. 
extremely rich source of contextual information: conversation, location, gesture, ambient sound, and so on. Information overload becomes negligible because the wearable learns the correlation between the wearers actions and provides only the resources it believes match his current needs. For example, at a business party the wearer may shake hands with a woman he knows hes met before, but he cannot remember her name. The wearable computer will sense the handshake, trigger its facerecognition system, identify the woman, and automatically display her contact information and the last piece of email the wearer received from her. 
Of course, this scenario is probably in the distant future, but a more immediately realistic example is automatic email response. The wearable receives a piece of email, judges it to be urgent, and alerts its wearer through a display. At the same time, it preloads the senders phone number into its wireless phone software, which is based on the wearers Rolodex. The wearer can reply to the email sender simply by telling 
the wearable to go ahead and initiate the phone call. This type of support, which is now feasible, is likely to be more common in the coming decade. 
Wearable computers can also aid communication and collaboration. Although teleconferencing hardware and software let desktop users communicate across continents, many occupations are inherently mobile. Thus, many opportunities for collaboration occur during spontaneous meetings, away from the computer. A wearable computer would be an obvious tool to support collaboration. Indeed, researchers at Carnegie Mellon University found that remote assistance significantly improves task performance in wearable applications.4 In their experiments, a technician wore a headmounted display and camera that let a remote expert see the technicians workplace. As the expert viewed what the technician saw, he sent relevant manual pages, which appeared on the technicians headmounted display. The CMU wearable allowed remote awareness and presentation, two of the collaborative support functions that wearable computers can exhibit. Others include remote presence, remote pointing, and remote manipulation.5 
computers are common in the workplace, companies are already applying the technology in select cases. The sidebar Up and Coming Applications describes the anticipated market in more detail. 
Two projects are noteworthy, the first because it demonstrates the benefits of using a generalpurpose wearable computer to support collaboration and performance in the workplace; the second, because it shows the potential of singleapplication wearables in a niche market. Applications by other companies such as Xybernaut and ViA have also been documented (see the sidebar Current Work on Wearables). 
has been exploring how wearable computers can help make aircraft manufacturing workers more productive. The companys goal was to streamline the process of isolating and repairing faults in Boeing 757 aircraft that were off the production line but had not yet flown. Before using wearable computers, mechanics would estimate what they thought the problem was, and then take the relevant manual pages with them as they crawled around the plane trying to verify their initial diagnosis. Often they needed additional or different pages and had to leave the plane to retrieve them. 
Initially, Boeing equipped each mechanic with a wearable computer that could access all the planes documentation, either from its own storage or through wireless networking. The wearable also guided mechanics through decisionmaking so that they could identify faults more quickly. 
A pilot project with a dozen mechanics ran for a month in early 1996. Mechanics used ViAs Via I wearable 486 computer and Virtual Visions headmounted display. A Boeing team, led by Chris Esposito, customized the software and hardware interface to satisfy unique interface requirements, such as being able to use the computer at an arbitrary orientation and in a harsh environment. The team also added a dial input device, developed by CMU, instead of an ergonomically unfavorable mouse, and experimented with speech input. With the dial, the mechanics could select menu items or check off list objects just as they would with a desktop mouse. 
Almost all the mechanics reacted positively to the wearable computer, finding it useful in their work. A third of the test group, mostly those working outside the plane, were concerned that the headmounted display would block their peripheral vision. This issue still needs to be addressed in future design generations. 
A second trial in 1997 explored how wearable computers could enhance collaboration among mechanics. Boeing researchers added a wireless link and Microsofts NetMeeting so that mechanics could communicate with their coworkers in the plane or with remote engineers in an office. The headmounted cameras sent images of the workplace where the mechanic was working. Speech recognition kept the system completely hands free. 
The trial was very successful. Mechanics in a factory in Southern California now use this configuration to conference with design engineers in Seattle, Washington, and Huntsville, Alabama, sending video and audio over Boeings highspeed intranet. Boeing is also working with airlines that want to use wearable computers to isolate faults at airports. The aim is to reduce delays (time on the ground) and repair turnaround time by using the wearable to provide expert guidance during diagnostic procedures. Savings to the airline are estimated to be tens of thousands of dollars per fault. 
Intelligence Symposiums Workshop on Interfaces for Wearable Computers; http://www. hitl.washington.edu/people/grof/VRAIS98/home. html. A workshop on interface aspects of wearable computing held in conjunction with the IEEE conference on virtual reality. 
 The First and Second International Symposia on Wearable Computers; http://iswc.gatech.edu/ wearcon97/default.htm and http://iswc.gatech. edu/default.htm. The ISWC, which debuted in 1997, is devoted to wearable computing. Both Web sites contain the complete text of the papers presented and streaming video of the talks given. 
http://www.xybernaut.com/ ViA Inc, ViA flexible PC; http://www.flexipc.com/ MicroOptical, unobtrusive headmounted dis
 The HIT Lab wearable computing group at the University of Washington; http://www.hitl. washington.edu/projects/ wearables/ 
 The University of Washingtons guide to wearable computing; http://www.hitl.washington. edu/projects/knowledge_base/wearable.html 
prototype of the worlds first fingermounted ring scanner in 1994. In early 1995, United Parcel Service asked Symbol to take this prototype and develop an armmounted computer and finger scanner that would let workers scan parcels as they loaded them into trucks at UPS warehouses. 
Symbol worked closely with UPS through the design process. Designers first observed current UPS work practices and then conducted extensive human factors research. From these findings, they produced a concept drawing and a dummy prototype that UPS workers could evaluate. The key acceptance challenge was ergonomics. To ensure the wearers comfort, designers padded the hard components and prevented them from moving around the wearers finger and arm. The arm mount went through 50 revisions (compared to the ring scanners 15). The key technical challenges were power and miniaturization. The scanner had to run for five hours at zero degrees Celsius on a battery that could fit into a wrist unit. The unit had to weigh less than 12 ounces, so the computer, scanner electronics, and wireless networking had to be miniaturized. 
Figure 2 shows the final productthe WSS 1000 which consists of an 8086 DOSbased computer that uses NECs V25 computer on a chip, a ringmounted bar code scanner with a range of 26 inches, and a wireless LAN. The prototypes were delivered to UPS for user testing. Each unit was used for 40,000plus hours to scan 400 to 500 parcels an hour. The work conditions proved far more rugged than anticipated; on some units; the plastic cases wore through, and the battery clip had to be redesigned a dozen times before it could withstand the constant use. User acceptance was also a problem. To address it, Symbol first had users work with a handheld scanner for a week, and 
then introduced them to the lighter, more ergonomic wristmounted scanner. After the handheld scanner, employees eagerly accepted the wrist scanner. 
In September 1996, after 18 months and $10 million in development, Symbol delivered 17,000 WSS 1000 wrist computers and scanners to UPS, which has since found them very effective in reducing the time to perform handsbusy tasks. Some users have come to work early to try the units, and for intensive applications, they consistently choose the wearable computers over handheld scanners. Symbol has sold an additional 13,000 units to customers such as Albertsons, FedEx, WalMart, Office Depot, and Sainsbury and is now working on improving the interface and scanning technology in a new product release. 
Figure 2. Symbol Technologies wearable barcode scanner and computer. The product is being used by United Parcel Service and has been sold to various retail chains. To date, user acceptance is high. 
One way to understand the progression of wearable computing is to look at the evolution of the timepiece. The first clocks were monumental works that only the rich or powerful could afford. Clock towers such as Big Ben in London are a legacy from the days when each town or village had a single timepiece. The invention of the lantern clock in the 1400s and the grandfather clock in the 1660s meant that each wealthy home could have their own timekeeping. 
John Harrison built the first pocket watch, a marine chronometer that could accurately determine the exact longitude of a ship. For the first time people had an easily portable timepiece with which to make and keep appointments and easily manage time. However, early pocket watches were expensive, were not constantly available, and required the use of at least one hand. These problems were overcome through the modern wristwatch first popularized in 1907 by Alberto SantosDumont, an aviator who wanted to tell time while keeping both hands free for pilot
ing. Aviators and soldiers in both world wars assured the success of the wristwatch, which is still the dominant technology for timekeeping. 
The mainframe computers of the 1950s are the village clock towers, while the desktop computers of the 80s are the grandfather clocks. We are now at the pocket watch stage of wearable computer development. We must wait until wearable computers become widespread before we will get the same benefits in managing information that wristwatches gave us in managing time. 
have practical value in the real world. However, to make wearables more widely applicable, designers need new interface metaphors and a better understanding of how wearable computing enhances collaboration. 
menuspointers, or WIMP, metaphor. Assumptions inherent in this metaphor make it inappropriate for wearable computers. First, WIMP interfaces see interaction with the computer as the users primary task. With wearable computers, interaction with the real world is the primary task. Second, WIMP interfaces assume the user has plenty of screen real estate and a pointing device. Wearable computers may have very limited screen space, and their input devices may have to be used with one hand, when out of the users view, and at an arbitrary orientationmaking pointing devices generally unsuitable. 
More fitting metaphors are Rhodes ambient and agent interfaces.6 These metaphors categorize input and output interfaces by how much user attention is required. Rhodes views these metaphors as points along input and output continuums. As Figure 3a shows, passive sensors such as microphones require no attention; a direct manipulation interface, on the other hand, requires the users full attention. Full visual and audio multimedia output demands a lot of user attention, but agent technologies automatically act on the users behalf and so require little. Between 
these extremes lie ambient interfaces, which use lowattention output modalities such as background noise and augmented reality interfaces that overlay information on the real world. The desired input and output modalities depend on the nature of the task and the information to be managed. For example, if the user is involved in an important meeting and does not want to be disturbed, a lowlevel ambient output would be most appropriate. On the other hand, if the wearable computer is being used in an emergency situation to locate disaster victims, an augmented reality overlay of tracking information on the real world would be more suitable. 
Alternative interface metaphors can also reduce the wearers cognitive load. Most current wearable applications that present information through a headmounted display use a fixed display. In this metaphor, information is presented in the same form and position, ignoring the wearers visual orientation. The disadvantage is that the information shown is limited to the physical resolution of the headmounted display, often as small as 320 240 pixels. To overcome this, designers can use a virtual spatial display that is larger than the physical display. The larger virtual spatial display lets people use their own visual orientation to see the information displayed. Experimental studies have found that, because people use their innate spatial abilities to find information, they can locate it 30 percent faster and retain more of it than with a fixed display.7 
Figure 4 shows the difference between the fixed and spatial displays. In Figure 4a, information is displayed as a flat page, all at once. The user sees the same information regardless of where he moves his head. In Figure 4b, the computer projects a virtual cylinder of information that surrounds the user. The user sees only part of the information at a time. To allow the user to view the rest of it, the wearable computer either rotates the information space about the wearers head or tracks his head as he looks about the space. To further enhance performance, interface designers can add spatial cues, such as threedimensional sound from the location of the target information, or visual cues that show the user which way to turn his head. 
support connections only between one local and one remote user. Studies at CMU4 and the University of Oregon5 show that wearables can significantly improve collaboration between user pairs. How wearable computers can enhance collaboration between larger groups is still an open question. As telephones incorporate more computing power and portable computers become more like telephones, there will be even greater pressure to use computing power to enhance communication. 
Figure 3. Continuums that measure the computer users (a) input and (b) output attention. Input attention measures to what degree the user must be involved in detecting input. Microphones are an example of the passive sensors on the left side of (a). Manipulative interfaces, such as Windows 95, are on the other end of the continuum. Output attention measures to what degree the user must be involved in producing output. 
Although the technology is just now becoming available, previous research in teleconferencing, collaborative virtual environments, and computersupported collaborative work suggest that a wearable conferencing space should have three key attributes: 
 Highquality audio communication for effective presentation of conversational content and audio cues. 
 Visual representations of the collaborators for understanding who is in the communication space, for recognizing their availability, and for nonverbal communication. 
 An underlying spatial model for mediating interactions so that gaze and body position cues can be used to convey communication information and so that the space can support dozens of simultaneous users. 
Figure 5 shows how designers can take the cylindrical spatial metaphor in Figure 4b and build a wearable conferencing space. In such a space, remote users are represented by static or live video avatars that surround the local user. As the remote users speak, the wearable computers CPU makes the audio appear to be coming from the spatial location of the avatars. In this type of interface, users could employ many of the same cues they use in facetoface conversation. They can turn and face the speakers they want to talk to, move closer to hear better, and hold side conversations. Users can choose their own views and spatial 
relationship to the other participants in the space. Thus, a wearable communications space could support dozens of simultaneous users, much like current collaborative virtual environments. 
Figure 4. Using the spatial display metaphor. In (a), the more conventional display mode, the display is fixed, and the wearer sees all the data at once and in one position. In (b), the spatial metaphor is a virtual cylinder of surrounding information, and the wearable computer either rotates the cylinder or tracks the wearers head as he looks around. The virtual cylinder lets users find information 30 percent faster than with a fixed display and remember its location more accurately. (Image courtesy of Nick Dyer) 
Figure 5. Spatial conferencing. The wearable computer makes incoming audio appear to be coming from the virtual speakers. These spatial cues let users treat participants in a way that more closely resembles collaborative work. (Image courtesy of Nick Dyer) 
Although the technology for fully implementing such an interface may be several years off, researchers at the University of Washingtons Human Interface Technology Laboratory, in collaboration with British Telecom, have already developed a working prototype. Figure 6 shows the view through the headmounted display. Remote collaborators are superimposed on the real world so that the user can continue working while receiving remote assistance. Studies show that the spatial cues let users easily distinguish between multiple simultaneous speakers.8 
A s the computer moves from desktop to coat pocket to the human body, its ability to help manage, sort, and filter information will 
become more intimately connected to our daily lives. In the next five years, we can expect to see wearable computing technology embedded in applicationspecific portable devices such as digital music players, cellular phones, or personal organizers. A few years after that, we should see more general wearable computers in common use in the mobile workplace. These wearables will combine communication, computation, and context sensitivity to enhance personal productivity. By the next decade, you may have a device that gives continuous access to computing and communications resources on a machine intelligent enough to know what youre interested in, when to give it to you, and how to present it in a manner most appropriate to what youre doing at the time. Artificial intelligence will augment human intelligence to make information management as natural as any other physiological function, freeing human intellect to focus on creative rather than computational function. 
Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment, Proc. First Intl Symp. Wearable Computers (IWSC 97), IEEE CS Press, Los Alamitos, Calif., 1997, pp. 7481. 
2. S. Mann, Smart Clothing: The Wearable Computer and WearCam, Personal Technologies, Vol. 1., No. 1., SpringerVerlag, Berlin, Mar. 1997. 
3. B. Rhodes, The Wearable Remembrance Agent: A System for Augmented Memory, Proc. First Intl Symp. Wearable Computers (ISWC 97) IEEE CS Press, Los Alamitos, Calif., 1997, pp. 123128. 
4. J. Siegel et al., An Empirical Study of Collaborative Wearable Computer Systems, Human Factors in Computing Systems: CHI 95 Conference Companion, ACM Press, New York, 1995, pp. 312313 
5. G. Kortuem, Issues in the Design of User Interfaces for Collaborative Wearable Computers, http://www.hitl. washington.edu/people/grof/VRAIS98/Kortuem.html. 
6. B. Rhodes, WIMP Interfaces Considered Fatal, http:// www.hitl.washington.edu/people/grof/VRAIS98/Rhodes. html. 
7. M. Billinghurst et al., An Evaluation of Wearable Information Spaces, Proc. IEEE Virtual Reality and Artificial Intelligence Symp. (VRAIS 98), IEEE CS Press, Los Alamitos, Calif., 1998, pp. 2027. 
8. M. Billinghurst et al., A Wearable Spatial Conferencing Space, Proc. Second Intl Symp. Wearable Computers, IEEE CS Press, Los Alamitos, Calif., 1998, pp. 7683. 
Mark Billinghurst is a researcher at the University of Washingtons Human Interface Technology Laboratory, where he works on the laboratorys wearable computing project. His current work involves using virtual reality techniques to develop interfaces for wearable computers, particularly interfaces that support collaboration on a wearable platform. He received an MPhil. from the University of Waikato in New Zealand. Contact him at grof@hitl.washington. edu. 
Thad Starner is an assistant professor at the Georgia Institute of Technology and cofounder of the MIT Media Laboratorys wearable computing project. His research interests are user modeling, augmented memory, augmented reality, intellectual collectives, and alternative power for wearable computers. In 1998 he received a PhD in media arts and sciences from the Massachusetts Institute of Technology. Contact him at thad@cc.gatech.edu. 
Figure 6. A prototype implementation of the conferencing concept in Figure 5, in which remote participants are superimposed on the local users real world. 
