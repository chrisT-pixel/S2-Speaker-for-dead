In this paper we introduce CityViewAR, a mobile outdoor Augmented Reality (AR) application for providing AR information visualization on a city scale. The CityViewAR application was developed to provide geographical information about the city of Christchurch, which was hit by several major earthquakes in 2010 and 2011. The application provides information about destroyed buildings and historical sites that were affected by the earthquakes. The geolocated content is provided in a number of formats including 2D map views, AR visualization of 3D models of buildings onsite, immersive panorama photographs, and list views. The paper describes the iterative design and implementation details of the application, and gives one of the first examples of a study comparing user response to AR and nonAR viewing in a mobile tourism application. Results show that making such information easily accessible to the public in a number of formats could help people to have richer experience about cities. We provide guidelines that will be useful for people developing mobile AR applications for cityscale tourism or outdoor guiding, and discuss how the underlying technology could be used for applications in other areas. 
Keywords: Mobile application, outdoor augmented reality, city visualization, earthquake and historical content. 
Index Terms: H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems Artificial, augmented, and virtual realities 
On September 4th 2010, a magnitude 7.1 earthquake hit the city of Christchurch in New Zealand and changed it forever. Since that time more than 10,000 aftershocks, including the most devastating earthquake on February 22nd 2011, have damaged the city and over 900 inner city buildings have been demolished. With nearly a third of downtown Christchurch gone it is difficult for people to remember what the city looked like or the important historical landmarks that have vanished. 
However, Augmented Reality (AR) technology can be used to go back in time and see the city as it was, both before and right after the devastating earthquakes. Over the last year we have developed a mobile AR application, CityViewAR, which allows users to see 3D virtual models of buildings put back on the real sites that they used to occupy (see Figure 1). 
One of the main uses for in mobile smart phone based AR is for providing geolocated information through an AR browser (e.g. Junaio [10] or Layar [11]). This type of application shows 
information on point of interest (POI) in the real world, such as buildings, businesses, and public transportations. In most cases, geographical information is shown as virtual bubbles with text and images of the related POI. 
The CityViewAR application is designed as an outdoor AR information browser application for providing geographical information related to the earthquakes that hit Christchurch. While there are existing historical records and information about the buildings, much of it is not easily accessible since it is scattered in different places, and are not organized in a locationoriented manner. The idea behind this application design was collecting this information and reorganizing it into a geolocated structure, and making it easily accessible through modern personal information technology, so that it can help people to understand and remember those historic sites damaged in the earthquakes. 
In addition to providing historical information about buildings, the CityViewAR application is also designed to provide onsite AR visualization of the buildings, allowing users to see a virtual 3D model of the building on the real site where it once was. 
In the next section we review related work that uses AR technology for presenting touristic, archeological and historical content. Then we describe details of the design and implementation of the CityViewAR application. We also describe the details of user studies that we have conducted, and design guidelines for developing similar mobile outdoor AR applications. 
Mobile outdoor AR has been a well researched field since Feiner et al. [2] have shown that an AR system can guide and assist users exploring outdoor environments. The work included an implementation of an early outdoor AR system designed to be worn by a user as a back pack, and the system visualized virtual tags on buildings to assist the user navigating in an urban environment. They also showed that mobile AR hardware could provide historical information on site as, such as older versions of buildings in view, or pictures of past events [4]. 
From the early days of mobile outdoor AR research, visualization of historical sites for tourism has been one of the main application areas. In the Archeoguide project, Vlahakis et al. 
[8] developed an outdoor AR system that guides users around archeological sites. The user was equipped with a wearable system [3] that ran an AR application for showing 3D models of historical buildings on archeological sites. 
Traditionally mobile outdoor AR systems required a significant amount of hardware which the users had to either carry on their back [2][3][6] or pull around on a cart [7]. However, with rapid development of mobile device technology, mobile phones have become powerful enough to run AR applications. 
As the smartphones become widely available, many mobile AR browser applications have become popular and commercially available [10][11]. These mobile outdoor AR applications started as an interface for showing geolocated information as icons floating in the real world, and recently developed to where they can visualize 3D models registered in the real world. However commerial AR browsers are designed for general purpose AR information overlay and have limitations when used to show large numbers of 3D models on a city scale. 
Compared to these general purpose AR browsers, CityViewAR was designed to be able to show large numbers 3D model of buildings in city scale AR visualization, and presenting various types of content including panorama pictures. In addition, our application has a tailormade interface which is designed around the content, contributing to a better overall user experience. 
While many mobile outdoor AR applications have been published [9], there have been few indepth user studies investigating the value of having an AR interface, compared to a nonAR map guide. So this paper makes a contribution by reporting our findings from a formal user study evaluating the CityViewAR application. This will provide a useful reference for those designing and developing mobile AR applications for tourism. 
As an information browser, the main function of the CityViewAR application is to allow the user to efficiently access geolocated information. The application takes advantage of builtin sensors on smart phones (e.g., GPS, electronic compass and accelerometer) to provide information based on the users current location. To meet different needs of the users, CityViewAR shows information using different visualization methods, including AR, interactive digital map, and list views. These three views are used as the main interfaces with which user could browse through the content and information provided. 
Figure 2 shows an overview of the navigational structure of the CityViewAR interface. There are three navigational layers of different screens of activity. The user starts from the first layer which provides general information about the application including the title and instruction screens. From the title screen, users can step into the browsing interface where they will be able to browse through the buildings and sites in different visualization styles, and then access various content including historical information, images and panorama pictures. 
The application is designed to start with the Map view (see Figure 3) which is more accessible independently from the users location, yet gives enough spatial context, and provides a familiar starting point. The user can easily switch into the other browsing views using icons located at the bottom right screen corner. The details of each view are described later in the following subsections. 
While most user interaction is done with the touch screen interface, motion sensors on the device are also used. Besides tracking the viewpoint in the AR view, CityViewAR also provides an interaction method based on the orientation of the device for automatically switching between the AR and map views, similar to other AR browsers (e.g. Junaio [10]). In the map view, besides 
touching a button on the screen, users can change to the AR view by holding the device up for couple of seconds with the camera looking above the horizon. In the AR view, if the user holds the device facing down for a couple of seconds, the application switches into the map view. 
In the AR view mode, the application shows virtual information overlaid on a live video camera background, making the virtual content appear in the real world. While most of the other AR browser software show geographical points of interest (POIs) as icons floating in the real world, CityViewAR use threedimensional (3D) models of demolished buildings, allowing users to see the virtual buildings onsite, as if they were still standing there (see Figure 1). 
To visualize the AR scene correctly registered to the real world, the application needs to know the camera parameters including position, orientation, and projection matrix. CityViewAR uses GPS sensor information for tracking the geographical position of the device, and electronic compass and accelerometer for measuring the viewing direction of the camera. Based on this tracking information, and the field of view of the physical camera, the parameters of the virtual camera are set to visualize virtual objects registered to the real world. In this process, the geographical coordinates (latitude and longitude) of POIs are converted into the Cartesian coordinates that are used for the computer graphics rendering. The coordinates are converted relative to the users position as the origin, based on the World Geodetic System 1984 standard [13]. While geographical coordinates only provide two dimensional positions for tracking, we take height of the users viewpoint into consideration based on heuristics assuming that users are usually standing in outdoor environments. 
Users can interact with the AR view using the touch screen interface. Touching one of the virtual buildings or icons in the AR scene will show a popup dialog with a brief description of the selected POI with additional icons that link to other content, such as text, images, audio or video clips (see Figure 4). The popup dialog is shown at the bottom of the screen in a screen registered manner, and a wedge from the popup dialog points toward the world registered POI. We chose the screen registered visualization instead of the world registered method, in order to make it easier to read the text information and interact with touch icons. This design choice was also made to prevent the AR view being cluttered with too much information. 
The AR view also has an inset radar view which shows the POIs around the user as small dots on concentric circles, where the center of the circles represents the users location. The orientation of the radar view is updated to match the users current azimuth, so that the user can recognize the relative locations of the points in the real world. This interface helps users to have a better understanding of the overall scene without having to switch into the map view. 
Like many other mobile outdoor AR applications [10][11], CityViewAR uses map and list interfaces to complement the AR view. These interfaces provide an overview of the POIs and allow users to access the information even when away from where the POIs are located. 
In the Map view, the POIs (the same set that is shown in the AR view) are shown as icons (see Figure 3). The users location and bearing information is shown as an oriented arrow. Users can select one of the icons to access content available for that point, including descriptions, pictures, audio and video clips. Different icons are shown on the map according to the type of the POI and provided content, giving users a hint of what they can expect by selecting it. The map view shares the same popup dialog with the AR view, providing consistent user experience between the two most used views (see Figure 5). The map can either be shown as an aerial photograph or a simplified street map both from Google maps. 
The list view shows the POIs as a list sorted in order of distance from the users current location. There is also a search box that allows people to directly enter the name of a building that they are searching for. Therefore users can search for a specific POI by its name or by browsing through the list of POIs, which is not available in the other views (see Figure 6). 
When the user chooses a POI using one of the browser views, the application presents various types of content related to the selected POI. There are three types of content for around a hundred buildings that are currently included in the CityViewAR application: text description, images, and panorama pictures. The application presents each type of content in different views. 
The Detail view (Figure 7a) provides a detailed description of the buildings including architectural information, historical information, and distance from the users current location. Users can press the icons in the detail view to see other views. For instance, opening a link to the Image Gallery (Figure 7b) will allow user to look at pictures of the building, or the link to the Map view will take the user to the location on the map where the building is located. 
While most of the POIs in the application represent buildings, some of them are locations where panorama pictures are available. When the user chooses to view this type of POI, an immersive 360 degree panorama picture will be presented on the screen (Figure 7c). Users can drag on the touch screen to pan the viewing direction, or tap on a button to activate the motion sensor, in which case the view direction of the panorama picture will be updated according to the direction where user is pointing the device. The panorama pictures were taken just a week after the February 2011 earthquake and show considerable earthquake damage. 
Figure 7: Views for different types of content: (a) Detail view, (b) Image Gallery, and (c) Panorama view (from top to bottom) 
During its development, the application has been demonstrated in public at two major events: once in September 2011 at an open house event at the HIT Lab NZ, and in December 2011 at the public launch of the application in Cashel street mall in the city centre of Christchurch. The application has also been available on the Android market since then as a free download. During these public demonstrations, we have received user feedback which was used to improve the application iteratively. In this section, we share these design improvements. 
GPS sensors have errors of at least 1020 meters, and so it is hard to have accurate enough tracking information for visualizing virtual buildings correctly registered to the real world. The problem gets worse if the user tries to look at a nearby virtual building at a distance within the error range, which we found common in how the CityViewAR application was used. While the error is unavoidable, we tried to overcome this problem by introducing a suggested AR viewpoint, similar to how suggested 
viewpoints are used in tourism. The AR viewpoints are shown as an icon on the map as other POIs, and users are suggested to visit these viewpoints to get a better (more accurately registered) AR experience. 
Originally, this function was design to automatically snap the users position to the viewpoint when the user gets close enough (e.g., within the GPS error range). However, in many cases the error was dynamically changing, hence the viewpoint kept snapping to the viewpoint on and off, which appeared to be more annoying for the user. We changed the design to only giving notice to the user when a viewpoint is nearby, and letting the user tap on an icon if he or she wants to use that viewpoint as their location. 
Introducing the AR viewpoints not only helped users to have better experience when using the application on site, but also became a tool for indirectly experiencing the AR view even away from the location where building information is available. 
The CityViewAR application has information and 3D models of more than 100 buildings. Loading the entire set of 3D models not only took time at startup, but also resulted in slow performance on the mobile device. We changed the application design to only load the 3D models of the POIs near enough to the users location, and update the set of visualized models as the user moves. In this way, the application performed better and we were also able to avoid the AR scene being cluttered with too many 3D models. While showing only nearby objects does not provide a perfect solution for correct visual occlusions, it worked as a simpler solution that demands less processing power and does not require 3D models of all of the real buildings, compared to other methods such as visibility culling or using occlusion masks. 
While presenting POIs of panorama pictures was relatively straightforward in the Map and List views, showing them in the AR view was more difficult. Initially we considered showing them as a floating icons or spheres. However, CityViewAR was designed to show streets of virtual buildings which already fill the visual display. Instead of cluttering the AR scene further by adding floating icons of panorama, we took a similar approach to that used when notifying the user about AR viewpoints. The AR view notifies users with an icon on the upper right corner of the screen when there is a panorama picture available nearby. The panorama then can be opened by tapping on the notification icon if the user wants to. 
Through performing public demonstrations outdoors, we discovered that the displays were very dim under direct sunlight, even those on highend mobile devices. We addressed this problem by redesigning the visual appearance of user interface with a high contrast color theme. In addition, we also adjusted the intensity of the virtual lights used for rendering the building models in the AR view, so that they would appear in brighter color on the screen. 
The CityViewAR application is developed based on the Google Android operating system and software development kit. The application is supported on a range of smart phones and tablet devices that run Android 2.2 or higher, and have the required sensors (i.e., camera, GPS, electronic compass and accelerometer). The geographical map data is based on the Google Map API service and the 3D building models are modeled and registered to the map using Google Sketchup software. The POI information is stored in a SQLite database included in the application itself, and the 3D buildings are rendered using the inhouse developed mobile outdoor AR framework [12] based on the Android SDK and OpenGL ES API. The latest version (v1.5) of the application includes over 110 buildings with 3D models, and about 20 
In order to evaluate the design of the CityViewAR application, we conducted two user studies. First we collected feedback through an online survey from users who had downloaded the application. Based on these results we have conducted a formal user study. 
We collected user feedback through an online survey for about a month starting from April 1, 2012. The notification to participate in the online survey was embedded in the latest update of the application (published in March 1, 2012), and was activated about a month later to give the users enough time to explore the latest version of the application. The application was designed to give a notification at the start up screen with a link to the online survey site. The survey questionnaire included usability questions, some asking to respond in 9point Likert scale, and some asking to answer in an open format. 
While about 500 users downloaded the version with the online survey notification, we received only 8 responses. Out of those, 2 responses appeared to be duplicates and one user was not able to use the AR view on his device, leaving only 5 valid records. 
According to the result, all of the participants answered that they have been using the app for more than a month, and they were living in Christchurch. Participants rated the overall satisfaction of the user experience as 6.2 on average (1: very disappointed ~ 9: very satisfied, SD = 2.28), and to the question how easy it was to use, they responded with 7 on average (1: very difficult ~ 9: very easy, SD = 1.87). On the questions asking how useful (1: no use ~ 9: very useful) and fun (or enjoyable, 1: not fun at all ~ 9: very fun) each browser view was, the AR view and the map view were ranked slightly higher than the list view (see Table 1). When the participants were asked to choose a view they liked from the three browsing views, all five participants answered that they liked the AR view most. 
Observing the positive ratings of the user experience offered by the AR, we decided to further investigate this in a formal user study. 
Question Mean Std. Dev. Overall satisfaction of the experience 6.2 2.28 How easy was the application to use 7 1.87 How useful was the AR view 7.17 1.92 How useful was the Map view 7 0.89 How useful was the List view 5.83 0.45 How fun/enjoyable was the AR view 7.5 1.30 How fun/enjoyable was the Map view 6.33 0.84 How fun/enjoyable was the List view 5.17 1.10 
A formal experiment was conducted in Cashel street which is about 200 meters long and one of the few streets open to the public in the city centre of Christchurch (most of the city centre is still closed due to safety concerns and ongoing demolition work). There used to be around 20 buildings on the street before the earthquake, but now only seven remain. Many of the now empty spots were replaced with temporary buildings built from container boxes. Out of over a hundred POIs included in the CityViewAR application, 13 buildings and 7 panorama pictures were located in the area where the user study took place. 
The study was conducted over three days from around lunch time and to approximately 3pm each day. On the experiment days 
there was no rain, some clouds, and a fine breeze. We used three Samsung Galaxy Tab devices with 8.9 inch size screen for the experiment. The device has Dualcore 1 GHz CortexA9 processor and 1GB of main memory. 
The CityViewAR application is designed for the general public and not with a specific population or user group in mind. Therefore we randomly approached people at the study location and asked if they were willing to participate in the research study. We offered a coffee voucher as an incentive for participation. 
We recruited 42 participants (15 female, 27 male) between 13 and 51 years (M = 30, SD = 11.75). 18 (43%) participants were in Christchurch at the time of the most devastating February 2011 earthquake. Half of them (51%) had little to no prior knowledge of the streets and buildings of Christchurch. Nine participants had not used a smart phone or tablet before and 22 were using such a device frequently. Three participants had used the CityViewAR application before. However, none of them used it in the city centre where the experiment took place. 
The goal of the user study was to explore if the AR elements enhanced the user experience. So, the study followed a between subject design with 21 participants using the application with the AR view enabled, and 21 participants using it with the AR interface being disabled. With the AR interface disabled condition, the participants could still use the Map and the List view, and all of the content including image and panorama pictures were available. The session started with a brief introduction and instructions on how to use all the applications main features. After this the participants were free to use and explore the application as they pleased. The study finished with a questionnaire asking demographic data, prior use of AR interfaces and the CityViewAR interface, general usability questions and the Game Experience Questionnaire (GEQ) [5]. The GEQ has 33 questions on game experience answered on a 5 point Likert scale (1 not at all; 5 extremely) and grouped into 7 subscales: Competence, Sensory and Imaginative Immersion, Flow, Tension/Annoyance, Challenge, Negative affect, Positive affect. Wording was changed for four questions from game to application. Furthermore we collected logging data (including GPS position, duration, switching between modes) and made notes about observed behavior. 
From the log files we extracted the overall distance the participants travelled and the duration of each session. We investigated the distance of travel as a partial measure of active exploration. Since the applications content is location based and informs the user of how the city looked before, we expect users to move to these specific locations. Moving between POI locations could provide partial evidence of how much the user was actively exploring the content. The usage duration was investigated as a measure of the level of interest in the content or the given interface. While the questionnaire provides a subjective measure of the engagement, we investigated the usage duration as an objective measure. 
The minimum distance travelled was 0 meters and the maximum 326 meters (M = 96.28, MD = 69.26, SD = 83.85) 1. Duration was between 95 seconds and 1137 seconds (M = 419.40, 
1 Some participants, especially in the Maponly condition, used the application sitting down and did not move around. 
MD = 353, SD = 236.30) 2. Both distance travelled and duration were not normally distributed so we used nonparametric MannWhitney Utests to analyse the data. 
A comparison of the groups with AR and without AR showed no significant difference for duration (U = 200.00, p = .62) or distance travelled (U = 167. 0, p = .18). Comparing participants who looked at the panoramas to those who did not, revealed that those who used the panorama feature used CityViewAR longer (M = 514.48, SD = 268.79) than participants who did not (M = 324.33, SD = 152.47; U = 125.50, p = .02). Results showed no significant difference for the distance travelled U = 180.00, p = .31). We found a tendency indicating that people who were not in Christchurch during the earthquakes used the application longer (M = 479.79, SD = 257.344) than people who witnessed the earthquakes (M = 338.89, SD = 181.838, U = 140.50, p = .06)). 
Figure 8 shows how long the participants in the two condition used the different views or modes provided by the CityViewAR interface. The AR group used the AR view around half of the time, and spent a quarter of their time with the map view and another quarter with the various information and picture views. The nonAR group spent a little bit more than half their time in the Map view. They used the image view on average 17 seconds longer than the AR group (U = 92.50, p &lt; .01). 
We asked four questions (answered on a 9point Likert scale) about the overall usability and experience (How was the overall experience with the app?; How helpful was the app for you to 
2 The data point with the minimum value could have been classified as mild outlier but was retained for further analysis to reflect realworld usage patterns. 
remember the buildings and the street?; How useful was the app for understanding what has been changed/lost due to the earthquakes?; How easy was the app to use?). The results showed no significant differences between AR and NonAR participants for these questions (Figure 9). 
Taken both groups together we did find that people who were in Christchurch during the earthquake found CityViewAR more useful to help them understanding what has been changed/lost due to the earthquakes (U = 63, p &lt; .01) than participants who were not present during the earthquakes. 
The GEQ has been developed for measuring game experience and to our knowledge it has not been used to measure AR experiences. Because of the limited n (42 participants) in this study, we currently cannot sensibly test if the proposed structure can be reproduced in our context as well using factor analysis. However, we checked reliability by testing the internal consistency of the subscales (see Table 2). 
Subscale Cronbachs Competence .86 Sensory and Imaginative Immersion .80 Flow .75 Tension/Annoyance Challenge Negative affect Positive affect 
reliability. This goes in line with findings from De Grove et al. [1] who found the Challenge subscale somewhat problematic. If we take all 33 questions together as a measure of overall experience we get = .86. 
The AR group judged their experience on all subscales slightly higher than nonAR users. While none of these differences is significant for the individual subscales, taking all questions together we found that AR showed a significantly higher mean experience (U = 139.50, p = .04). However, the actual difference is rather small (M = 3.11, SD = 0.46 compared to M = 2.82, SD = 0.37) (see Figure 10). No significant differences were found for panorama usage. 
We found a weak to moderate correlation between session duration and the Flow subscale (r = 0.30, p = .05). This can be seen as an indication of validity of this subscale, which includes questions such as I lost track of time and I was deeply concentrated in the application. 
In the questionnaire we also asked questions that required participants to freely write down their opinions. These questions allowed participants to state multiple choices if they wanted to. To the question asking what feature of the application they liked most, eight participants in the AR group mentioned they liked the AR view most. However, from the NonAR group no one mentioned the Map view, instead about half of them mentioned they liked the panorama pictures most. Table 3 summarizes the answers to this question. 
 AR NonAR Total Participants who gave answer 19 16 35 AR view 8 (42.1%) N/A N/A Map view 2 (10.5%) 0 ( 0%) 2 ( 5.7%) Panorama view 4 (21.1%) 10 (62.5%) 14 (40 %) Rich information available 3 (15.8%) 6 (37.5%) 9 (25.7%) Easy and simple user interface 4 (21.1%) 0 ( 0%) 4 (11.4%) * Values in number (percentage) of participants. 
application (see Table 4). About half of the participants answered that they had no specific problem with using the application. The most common problems reported was the application becoming intermittently unresponsive to touch. The NonAR group reported this problem twice as much. Also, the NonAR group reported that the graphical user interface elements (such as icons) were not so intuitive. 
On the other hand, the AR group reported more problems while holding the device to look at the AR scene, which included glare on the screen and unintended touch operations. Also, two participants in this group reported that the tracking was not good and the AR scene was not well registered. 
No problem 11 (55%) 7 (38.9%) 18 (47.4%) Lag, unresponsive to touch 3 (15%) 6 (33.3%) 9 (23.7%) UI design not so intuitive 0 ( 0%) 6 (33.3%) 6 (15.8%) Unintended touch on screen 3 (15%) 0 ( 0%) 3 ( 7.9%) Glare on screen 2 (10%) 0 ( 0%) 2 ( 5.3%) Tracking error 2 (10%) 0 ( 0%) 2 ( 5.3%) * Values in number (percentage) of participants. 
 AR NonAR Total Participants who gave answer 21 21 42 More information and content 9 (42.9%) 8 (38.1%) 17 (40.5%) Guided tour paths 8 (38.1%) 9 (42.9%) 17 (40.5%) Browse content in order of time 7 (33.3%) 5 (23.8%) 12 (28.6%) Leave comments from users 7 (33.3%) 4 (19.0%) 11 (26.2%) Take picture with virtual bldgs. 5 (23.8%) 2 ( 9.5%) 7 (16.7%) Sharing content from users 3 (14.3%) 4 (19.0%) 7 (16.7%) Other 0 ( 0%) 1 ( 4.8%) 1 ( 2.4%) * Values in number (percentage) of participants. 
We asked participants what features they would like in a future version of the application. Participants could answer this question by either choosing from the list of features that we are planning to integrate, and/or giving open comments. Having more information and content and presenting guided tour paths were the most preferred options. Table 5 shows details of the participants answer. All of the participants chose from the given list, except one participant wished having links to other websites or businesses. 
While conducting the user study, we observed that the NonAR group was tending more to sit down and use the application without moving around, even after being instructed to actively explore the environment at the beginning of the experiment. 
Figure 11 shows the participants movement paths on the Google Earth map. The red line shows the path of the AR group and the light blue line shows that of the NonAR group. Considering GPS inaccuracy, we filtered out the location update records that had more than 15 meters error. The path of the AR group appears to cover a wider range, showing their tendency to move around more. 
Figure 11: User location log information plotted on the Google Earth (Red: with AR / Light Blue: without AR) 
The mean value of distance traveled of the AR group was higher (M = 114.56, SD = 91.40 compared to M = 78.01, SD = 73.19, in meters), although we found no statistically significant difference between the two groups (U = 167.00, p = 0.18). According to our observation we believe that this was partially affected by the panorama pictures. The panorama pictures were presented with the view direction being updated by the motion sensors, which gave a similar user experience to that of the AR view. We observed that some of the participants in the NonAR group started moving around as they discovered the panorama pictures. 
One of the common problems observed with the AR users was having trouble with the glare on the screen. When using the AR view or the panorama view with the orientation sensor, users often struggled with bright reflections on the screen, making it hard to see the content. Another problem commonly found was making unintentional operations such as touching on the screen or pushing a button while holding the device in the AR view. 
We found a small, though statistically significant difference in the overall experience between the people who used our application with and without the AR interface (see Figure 10). The overall user experience of the CityViewAR application appears to be more affected by the content it provided. In particular, the panorama pictures were very popular (see Table 3), and the 
people who saw the panorama pictures tended to use the application longer. We found that people who were not in Christchurch during the earthquake tended to use the application longer. This indicates that visitors and tourists appeared to be more interested in the story of the earthquake the application. 
While the participants used the map view as a browsing tool for discovering POIs and its content, the AR view appeared to be considered more like a mixture of the browsing interface and the content itself. None of the participants in the NonAR group mentioned the Map view as their favorite feature of the CityViewAR application. Instead, many of them chose panorama pictures as their favorite. On the other hand, about 40% of those in the AR group picked the AR view as their favorite feature. The virtual buildings shown in the AR view were indeed designed as application content, while AR also is an interface that links to other content that is related to the buildings. 
Although the tracking technology was not highly accurate, not many users commented on this as a problem (see Table 4). Based on the observations during the experiment, most of the participants who were using the AR interface were more focused on the appearance of the virtual buildings rather than their exact location. This suggests that some limitations of the interface can be overcome by using compelling content. AR viewpoints is another example in the CityViewAR design to overcome the limitations in tracking accuracy by encouraging users to move to the known locations where they can have a better AR experience. 
While the AR and Map views were actively used by the participants, the List view was used less (see Figure 8). About 70 percent of the participants (14 in the AR group and 15 in the NonAR group) never used the List view, and most participants in both group spent less than 10% of their time in the list view. 
Both, from the answers to the open questions and our observation during the experiment, we found that some of the participants in the AR group were experiencing problems with glare on the screen and unintended touch. While these limitations are mainly based on the device itself rather than the application, we can ease some of these problems by improving the user interface design. For example, we enhanced color contrast for both visual design and the rendering setup in the CityViewAR application. 
Based on these results, we provide the following guidelines for developing mobile outdoor AR tourism applications: 
4) A List view might be used less often than the AR or map views. However, it could be considered as a complementary tool for the users who prefer to use it. 
5) Consider the physical limitations of the device, and try to overcome issues with good user interface design. 
In this paper we described the design and implementation details of the CityViewAR mobile outdoor AR application. The application was developed to provide geographical information in the city of Christchurch that was affected by devastating earthquakes. The main design feature of the application is visualizing 3D models of the buildings using AR technology, showing the city as it was before the earthquake. We described the iterative design improvements we made based on user feedback. 
We also reported the results from a user study comparing user response to using CityViewAR with the AR interface either enabled or disabled. The results showed that the AR interface, as both a browsing interface and content view, can contribute to providing an enhanced user experience. 
For future work, we are planning a longer term user study to gain more indepth insight into mobile outdoor AR interfaces. Based on the collected user feedback, we are planning to improve the design of the application and add more features, such as providing information through an online server, and improving AR tracking with hybrid tracking methods using computer vision techniques. 
[1] F. De Grove, J. Van Looy, and C. Courtois. Towards a Serious Game Experience Model: Validation, Extension and Adaptation of the GEQ for Use in an Educational Context. In L. Calvi, K.C.M.Nuijten, H. Bouwknegt (Eds.) Playability and player experience, pp. 4762, Breda, Netherlands: Breda University of Applied Sciences, 2010. 
[2] S. Feiner, B. MacIntyre, T. Hllerer, and T. Webster. A touring machine: Prototyping 3D mobile augmented reality systems for exploring the urban environment. In Proc. ISWC '97 (First IEEE Internaional Symposium on Wearable Computers), pp. , October, 1997. 
[3] T. Gleue and P. Dhne. Design and implementation of a mobile device for outdoor augmented reality in the archeoguide project. In Proceedings of the 2001 conference on Virtual reality, archeology, and cultural heritage (VAST '01). ACM, New York, NY, USA, pp. 161168, 2001. 
[4] T. Hllerer, S. Feiner, J. Pavlik, Situated Documentaries: Embedding Multimedia Presentations in the Real World, In: Proc. ISWC '99 (Third Int. Symp. on Wearable Computers), San Francisco, CA, October 1819, 1999, pp. 7986, 1999. 
[5] W.A. IJsselsteijn, Y.A.W. de Kort, and K. Poels. (in preparation). The Game Experience Questionnaire: Development of a selfreport measure to assess the psychological impact of digital games. Retrieved online on Sept. 5, 2012, from: http://www.citeulike.org/user/mjparnell/article/4934050 
[6] W. Piekarski, D. Hepworth, V. Demczuk, B. Thomas, and B. Gunther. A mobile augmented reality user interface for terrestrial navigation. In Proc. of 22nd Australasian Computer Science Conference, pp. 122133, 1999. 
[7] H. Schndelbach, B. Koleva, M. Flintham, M. Fraser, S. Izadi, P. Chandler, M. Foster, S. Benford, C. Greenhalgh, and T. Rodden. The augurscope: a mixed reality interface for outdoors. In Proceedings of the SIGCHI conference on Human factors in computing systems: Changing our world, changing ourselves (CHI '02). ACM, New York, NY, USA, pp. 916, 2002. 
[8] V. Vlahakis, N. Ioannidis, J. Karigiannis, M. Tsotros, M. Gounaris, D. Stricker, T. Gleue, P. Daehne, and L. Almeida. Archeoguide: An Augmented Reality Guide for Archaeological Sites. IEEE Computer Graphics and Applications 22 (5), pp. 5260, 2002. 
[9] Z. Yovchevaa, D. Buhalisb, and C. Gatzidisc. Overview of Smartphone Augmented Reality Applications for Tourism. In eReview of Tourism Research (eRTR), Vol. 10, No. 2, pp. 6366, 2012. Retrieved online on Sept. 5, 2012, from: http://www.ifitt.org/admin/public/uploads/eRTR_SI_V10i2_Yovche va_Buhalis_Gatzidis_6366.pdf 
[10] Junaio. http://www.junaio.com [11] Layar. http://www.layar.com [12] Mobile Outdoor AR Framework. http://www.hitlabnz.org/mobileAR [13] World Geodetic System 1984 (WGS 84). 
&lt;&lt; /ASCII85EncodePages false /AllowTransparency false /AutoPositionEPSFiles false /AutoRotatePages /None /Binding /Left /CalGrayProfile (Gray Gamma 2.2) /CalRGBProfile (sRGB IEC619662.1) /CalCMYKProfile (U.S. Web Coated \050SWOP\051 v2) /sRGBProfile (sRGB IEC619662.1) /CannotEmbedFontPolicy /Error /CompatibilityLevel 1.6 /CompressObjects /Off /CompressPages true /ConvertImagesToIndexed true /PassThroughJPEGImages true /CreateJobTicket false /DefaultRenderingIntent /Default /DetectBlends true /DetectCurves 0.0000 /ColorConversionStrategy /LeaveColorUnchanged /DoThumbnails true /EmbedAllFonts true /EmbedOpenType true /ParseICCProfilesInComments true /EmbedJobOptions true /DSCReportingLevel 0 /EmitDSCWarnings false /EndPage1 /ImageMemory 524288 /LockDistillerParams true /MaxSubsetPct 100 /Optimize true /OPM 0 /ParseDSCComments false /ParseDSCCommentsForDocInfo false /PreserveCopyPage true /PreserveDICMYKValues true /PreserveEPSInfo false /PreserveFlatness true /PreserveHalftoneInfo true /PreserveOPIComments false /PreserveOverprintSettings true /StartPage 1 /SubsetFonts true /TransferFunctionInfo /Remove /UCRandBGInfo /Preserve /UsePrologue false /ColorSettingsFile () /AlwaysEmbed [ true ] /NeverEmbed [ true ] /AntiAliasColorImages false /CropColorImages true /ColorImageMinResolution 150 /ColorImageMinResolutionPolicy /OK /DownsampleColorImages false /ColorImageDownsampleType /Bicubic /ColorImageResolution 300 /ColorImageDepth1 /ColorImageMinDownsampleDepth 1 /ColorImageDownsampleThreshold 1.50000 /EncodeColorImages true /ColorImageFilter /DCTEncode /AutoFilterColorImages true /ColorImageAutoFilterStrategy /JPEG /ColorACSImageDict &lt;&lt; /QFactor 0.15 /HSamples [1 1 1 1] /VSamples [1 1 1 1] &gt;&gt; /ColorImageDict &lt;&lt; /QFactor 0.15 /HSamples [1 1 1 1] /VSamples [1 1 1 1] &gt;&gt; /JPEG2000ColorACSImageDict &lt;&lt; /TileWidth 256 /TileHeight 256 /Quality 30 &gt;&gt; /JPEG2000ColorImageDict &lt;&lt; /TileWidth 256 /TileHeight 256 /Quality 30 &gt;&gt; /AntiAliasGrayImages false /CropGrayImages true /GrayImageMinResolution 150 /GrayImageMinResolutionPolicy /OK /DownsampleGrayImages false /GrayImageDownsampleType /Bicubic /GrayImageResolution 300 /GrayImageDepth1 /GrayImageMinDownsampleDepth 2 /GrayImageDownsampleThreshold 1.50000 /EncodeGrayImages true /GrayImageFilter /DCTEncode /AutoFilterGrayImages true /GrayImageAutoFilterStrategy /JPEG /GrayACSImageDict &lt;&lt; /QFactor 0.15 /HSamples [1 1 1 1] /VSamples [1 1 1 1] &gt;&gt; /GrayImageDict &lt;&lt; /QFactor 0.15 /HSamples [1 1 1 1] /VSamples [1 1 1 1] &gt;&gt; /JPEG2000GrayACSImageDict &lt;&lt; /TileWidth 256 /TileHeight 256 /Quality 30 &gt;&gt; /JPEG2000GrayImageDict &lt;&lt; /TileWidth 256 /TileHeight 256 /Quality 30 &gt;&gt; /AntiAliasMonoImages false /CropMonoImages true /MonoImageMinResolution 1200 /MonoImageMinResolutionPolicy /OK /DownsampleMonoImages false /MonoImageDownsampleType /Bicubic /MonoImageResolution 1200 /MonoImageDepth1 /MonoImageDownsampleThreshold 1.50000 /EncodeMonoImages true /MonoImageFilter /CCITTFaxEncode /MonoImageDict &lt;&lt; /K1 &gt;&gt; /AllowPSXObjects false /CheckCompliance [ /None ] /PDFX1aCheck false /PDFX3Check false /PDFXCompliantPDFOnly false /PDFXNoTrimBoxError true /PDFXTrimBoxToMediaBoxOffset [ 0.00000 0.00000 0.00000 0.00000 ] /PDFXSetBleedBoxToMediaBox true /PDFXBleedBoxToTrimBoxOffset [ 0.00000 0.00000 0.00000 0.00000 ] /PDFXOutputIntentProfile (None) /PDFXOutputConditionIdentifier () /PDFXOutputCondition () /PDFXRegistryName () /PDFXTrapped /False /CreateJDFFile false /Description &lt;&lt; /ENU () &gt;&gt; &gt;&gt; setdistillerparams &lt;&lt; /HWResolution [600 600] /PageSize [612.000 792.000] &gt;&gt; setpagedevice 
