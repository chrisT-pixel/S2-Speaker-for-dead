ABSTRACT Recently several researchers have developed augmented reality books which involve overlaying virtual content onto the pages of a real book. In this paper, we extend this general concept by adding virtual visual and auditory enhancements to an already published book. Together with the author and professionals in education we have explored various alternatives of combining virtual and real content, new dedicated interactions techniques, and visual effects to enhance immersion. In this paper we report on the design and development of a new type of mixed reality book. We also summarize user feedback collected during different user trials and demonstrations of the prototype. 
1. INTRODUCTION Over the last two decades there have been a number of efforts to replace or enhance real books with digital equivalents. Most recently, progress in eInk display technologies have lead to the development of electronic books offering better visual quality for reading. This continues a long line of advances aimed at enhancing the traditional printed book with electronic features, such as audio books, multimedia CD ROM books, online books, and electronic books readers. 
In [9], Marshall et al. have shown that users still love the physicality of a real book because it offers a broad range of advantages, such as: transportability, flexibility, robustness, etc. These factors support research into another future for books: digitally augmenting and enhancing real books, rather than seeking to replace them entirely. This combines the advantages of physical books with new interaction possibilities offered by digital media. 
Figure 1: The House That Jack Built: Augmenting and mixing pictorial content of a real book with virtual content (2D images, 3D smoke). 
is the use of Augmented Reality (AR). For example Billinghurst et al. [3] developed an AR book (MagicBook) in 2001. The key element of the MagicBook was for users to be able to see virtual content superimposed over real book pages in an AR view and then transition into a virtual reality view to experience a fully immersive view of the data. 
Since then many projects have followed up on the idea of superimposing virtual content over book pages (e.g. [1]), however, most AR book realizations considered the book only as a physical container. Little consideration was given to the richness and aesthetics of the pictorial content of the physical book and the reproduction of the natural interaction with a real book was limited to the action of flipping between pages. Finally, a large part of the research has been going toward the improvement of the underlying technology (e.g. [11], [7]), rather than the exploration of the engagement or the immersion with this type of electronic book. 
To explore the notion of reader immersion and engagement with a visually augmented book, we created a new type of mixedreality book (Figure 1), reconsidering the importance of the aesthetics of real illustrations. We aim to investigate how to design better symbiosis between new technology and a traditional medium and therefore a less disruptive reading experience. 
During several demonstrations (e.g. at CHI2007 [6]) we have gathered information and feedback helping us to refine the design and requirements for further developments. In general we follow a similar approach as the Listen Reader pro
The most relevant works on design for augmented reality books are Zhou et al. [12] and Saso et al. [10]. Zhou et al. combined the interface of a foldable physical toy with augmented reality to create a new type of storytelling application. Saso et al. presented Little Red, an augmented reality book using a colored background of a physical book as a playground for a virtual storytelling. They integrated interactive features, based on the marker embedded in the book, which users could manipulate to alter the story. Our work is in a similar direction. We generalize the work from Saso et al., further exploring the design space, and develop and conceptualize new interaction techniques while using real metaphors like those developed by Zhou. 
The contributions of this paper are a presentation of the new features and concepts we have developed with the mixed reality book and the issues uncovered during our research. 
2. THE MIXEDREALITY BOOK 2.1 Design and Development Process The book we chose is The House that Jack Built, an illustrated book by Gavin Bishop, a leading New Zealand childrens book author. It tells a story about European settlers arriving in New Zealand and the related cultural confrontations and struggles. The book was published in 1999 and is used in schools to discuss historical and cultural issues of early European settlement. The balance of educational values, narrative and pictorial content motivated our choice for this book. 
An indepth page per page analysis with the author helped us to better understand what he was trying to convey with the story. We analyzed important items and concepts for each page, and discussed how different virtual content, immersive effects or interactive actions could best be used to support and emphasize the meaning of these items. In several iterations, we demonstrated progress of the application to the author, got his feedback, discussed new implemented items and concepts such as interaction techniques or new assets, and refined the prototype. 
Each of the books pages provides a different interactive experience. For example, Figure 2 illustrates the design we developed for page three with the virtual content, interactive features, and their associated meaning. When opening this page the user hears the bells of Big Ben and port sounds. The surrounding of the page is visually augmented with a virtual sea. Using a real paddle (shaped like a ship) the user can trigger a virtual ship (2D) that sails from London to New Zealand, by putting the paddle next to the virtual boat in dock in London. As the ship passes Australia the users hears didgeridoos and, upon the ships arrival in New Zealand, bird sounds and a Maori welcome chant. The book has 20 pages, therefore we can only describe selected examples of our work here. 
The prototype has been developed with our AR framework ([8]) which gave us the possibility to explore the design (such as the layout of elements) without relying on dedicated technology (for example a specific tracking technology). Over 
The animated ship shows the journey of European settlers to New Zealand. Different sounds underpin cultural aspects of countries the ship passes. The virtual surrounding sea immerses the reader. 
Figure 2: Example of the augmentation of page 3: choice of the features from the design space and associated meaning 
the course of the development this also gave us the opportunity to choose appropriate technologies and refine the setup to provide the best user experience. 
2.2 The User Experience The House that Jack Built book is usually shown on a table with a pair of speakers for ambient and 3D sound (Figure 3). For visualization and tracking we can either use an AR handheld device with attached camera [5] or a handheld camera manipulated by the user and a computer screen behind the book. The former provides a more personal and immersive experience with the book, while the latter can be used for collaborative experiences and public demonstrations. 
Figure 3: A user interacting with the book: tabletop setup with augmented book in the center, visualization through an AR handheld display, and background and 3d sound through speakers. 
The book offers an audiovisual experience. We explored the use of different 3D graphics such as static models, animated models, and particle effects. With many animations and models we use different elements of the design space such as animated objects coming from outside the book, replication of elements in 3D and 2D, and 2D animation moving over the page, to name a few examples.
We also have implemented different sound effects: background sounds, sounds associated with animation, or 3D sound. Figure 4 (a) shows a page with three virtual 2D objects replacing their respective real content counterpart (to provide visual guidance for the user). Each of these models (a horse, fire and seagulls) have been associated with a 3D sound which means that the sound is modulated spatially as a function of the position of the user relative to the page. For example, when the user moves closer to the fire the respective fire sound gets louder. 
Other features include immersive effects produced by augmenting the surroundings of pages with the scenery illustrated in the book such as sea, landscape, and sky (e.g. 3D clouds, see Figure 4 (b)). We also used a darkening effect to guide the user to focus on specific parts of the pages. 
Figure 4: Examples of augmented pages with 2D pictures and 3D smoke (a); 3D model (house) and immersion through augmentation of the surround (clouds) (b); cinematic effect (darkened area) (c)); popup textbox with gaze interaction (d); animation of a virtual boat through paddle interaction and augmentated sea in the surround (e+f). 
It was important for us not to overload the pages with additional virtual content and features or to completely substitute the actual book content with virtual content. We limited the amount of the interactive features in the book, which could impact on the narrative by interrupting the flow of reading ([4]). So we tried to implement features in a way that they would not disturb the story, but accentuate the meaning of the story. Therefore, on some pages we chose to add just a few elements or very subtle enhancements. Moreover, we only integrated two types of interaction (tangible interaction and gaze interaction) to not introduce too much complexity, and only one interaction category (positioning). 
The gaze interaction developed is a gazecontingent approach, which means that an action is automatically triggered if the 
user is looking at a specific item. A cursor is displayed in the middle of the screen to indicate the point being used for the gaze selection. For example, Figure 4 (d) shows a textbox with additional information appearing when the user is looking at a specific augmented element in the book (i.e. the cloak, the fabric, tattooed face). We used the gaze in three forms: triggering 3D sound, starting an animation (of an object or of the camera), and displaying additional information. 
Tangible interaction is done with dedicated paddles. Rather than using a generic paddle, we chose to design taskspecific paddles for the respective pages. The user can grasp the paddle attached to the bottom of the page and use it for interacting with the content. This was done to guide the user and show on which page the paddle can be used. Also the outer shape of the paddles have been designed according to the element or interaction it can trigger, for example a paddle in the shape of a boat is used to interact with a boat on page 2. The boat paddle on page 2 triggers an event by proximity (putting the paddle next to the boat) and the house paddle on page 3 can be used to pick up a virtual 3D house from the book to have a closer look at it (see Figure 4 (b,c,e). 
3. USER FEEDBACK We presented the different prototypes of The House that Jack Built book at four public demonstrations in our lab (approximately 100 participants each time) and at the CHI2007 conference as an interactive demo. 
During these demonstrations we observed the user behavior in different scenarios: free use (users discover how the system works without assistance), assisted demonstrations (showing the features and asking users to experiment with different pages), controlled demonstrations (showing the demo and asking for user feedback). All those demonstrations provided us with valuable user feedback. The demonstration at CHI2007 gave us the opportunity to brainstorm with different ethnographers, HCI specialists and designers and get their feedback and ideas for further developments. 
The overall feedback about the prototypes was very positive. People liked to discover the system and interact with the various features. They were particularly amazed by the visual effects and the animations (e.g. the morphing of the cow associated with a darkening filter effect). A large part of their questions were related to the system development, content development, the potential distribution of the application to end users, and how users can use it in their homes. 
Discussion with ethnographers helped us to refine the design of the book. This was very helpful for developing various measures for user guidance. Many comments from designers were directed to the aesthetics of the prototype and the presence of the markers and their distracting effect. 
Sessions in which people used the prototype with the handheld device and without any initial training or explanation (e.g. at CHI2007) revealed some very important issues. In most other demonstrations we have used a computer screen so that we could demonstrate the prototype to a wider audience. This generally reduced the need for a participant to
discover the system on their own. After a short time users who discovered the system freely were able to properly use the system, observe animations, and go through the pages. Some users started to use the handheld device like a magnifying glass and explored the pages for interactive content (there should be something to see or to do). Most understood the role of the markers (if present) and that they had to be in the field of view of the camera. Since we did not integrate generic visual guidance for a user to interact with the paddle, it was often not used and the users just flipped to the next page. 
The assisted demonstration gave us a better chance to observe how the users manipulated the interaction paddles. The users also found the handheld device easy to use and enjoyed observing the different 3D static or animated elements. As they explored these elements we observed that they often moved very close up to the object to observe the details, which sometimes resulted in unstable tracking. 
The users could use the gaze interaction quite successfully, especially for the 3D sounds. However, using this technique for triggering the popup textboxes proved to be more difficult. This might be explained by the proximity of the three interactive hotspots that triggered the popups, or the relatively small size of the target for the textboxes. When users swept over these areas, all three were sometimes triggered almost simultaneously which was rather confusing. 
In the public sessions we also could observe forms of collaborative behavior with some audience members discussing and indicating where to look at and how to interact. 
One of the main issues we found, however, was related to the tracking technology. We realized that accommodating normal user behaviour puts high demands on the required tracking robustness. This is not only true for novice users. As the users understood the concept of the book, they generally started to use the system in a similar way as they would with a real book. This could result in wide, fast and jerky movements. In addition, many users liked to get very closeup to the pages. Even with combined markerbased and NFT, the creation of shadow artifacts, occlusions, and reduced image quality/resolution lead to failures in tracking and consequently to user frustration. 
4. DISCUSSION In this paper we have explored several research questions for the development and study of future visually augmented books. 
Using a real physical book for the development of a visually augmented mixedreality book has proven to be an excellent choice with respect to user enjoyment, engagement and usability. Nevertheless, this also has some drawbacks. For instance, the affordances of the book result in booklike interaction by the users (e.g. quickly scanning the pages, and closeup inspection) and this brings challenges in terms of technology deployment: how to make the tracking robust enough to ensure a pleasurable reading experience, how to enhance the quality of the visualization devices such as camera resolution or the field of view of the display. 
Our current approach was focused on storytelling books. However, we also would like to explore other types of books such as science text books. Although entertainment aspects might be not as important for such applications, user engagement is a definite key issue for educational books. Therefore it would be important to explore how we can enhance learning experiences with the possibilities mixedreality books offer. 
Acknowledgments We would like to thank all the people who have contributed to this project for the last years: Gavin Bishop, Kurt Adams, Jens Hopfer, Charles Han, Jung Shin and Claudia Nelles. 
instructionsa fusion of augmented reality and printed learning materials. In Advanced Learning Technologies (ICALT 2005), pages 213215, 2005. 
[2] M. Back, J. Cohen, R. Gold, S. Harrison, and S. Minneman. Listen reader: an electronically augmented paperbased book. In CHI 01, pages 2329, New York, NY, USA, 2001. ACM. 
[3] M. Billinghurst, H. Kato, and I. Poupyrev. The magicbookmoving seamlessly between reality and virtuality. IEEE Comput. Graph. Appl., 21(3):68, 2001. 
[4] H. Gomez. Parent and child reading, designing for an interactive, dimensional reading experience. In Proceedings of Technology for Interactive Digital Storytelling and Entertainment, 2003. 
[5] R. Grasset, A. D. Andreas, and M. Billinghurst. Humancentered development of an ar handheld display. In ISMAR 2007, 2007. 
[6] R. Grasset, A. Dunser, H. Seichter, and M. Billinghurst. The mixed reality book: a new multimedia reading experience. In CHI 07 Extended Abstracts, pages 19531958, New York, NY, USA, 2007. ACM. 
[7] S. Gupta and C. Jaynes. The universal media book: tracking and augmenting moving surfaces with projected information. In ISMAR 2006, 2006. 
[8] J. Looser, R. Grasset, S. Hartmut, and M. Billinghurst. Osgarta pragmatic approach to mr. In ISMAR 2006 Industrial Augmented Reality Workshop, 2006. 
[9] C. C. Marshall. Reading and interactivity in the digital library: Creating an experience that transcends paper. In Proceedings of CLIR/Kanazawa Institute of Technology Roundtable, 2005. 
[10] T. I. Saso, K. Iguchi, and M. Inakage. Little red: storytelling in mixed reality. In SIGGRAPH 03 Sketches &amp; Applications, pages 11, New York, NY, USA, 2003. ACM. 
[11] N. Taketa, K. Hayash, H. Kato, and S. Nishida. Virtual popup book based on augmented reality. In HCI 2007, pages 475484, 2007. 
[12] Z. Zhou, A. D. Cheok, J. Pan, and Y. Li. An interactive 3d exploration narrative interface for storytelling. In IDC 04: Proceedings of the 2004 conference on Interaction design and children, pages 155156, New York, NY, USA, 2004. ACM.
