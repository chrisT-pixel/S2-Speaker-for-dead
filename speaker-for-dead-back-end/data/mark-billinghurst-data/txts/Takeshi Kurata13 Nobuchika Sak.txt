Takeshi Kurata13 Nobuchika Sakata34 Masakatsu Kourogi3 Hideki Kuzuoka4 Mark Billinghurst12 1Human Interface Technology Lab, University of Washington, Seattle 
2Human Interface Technology Lab NZ, University of Canterbury, Christchurch, NZ 3AIST, Japan 4University of Tsukuba, Japan 
kurata@ieee.org, {sakata, kuzuoka}@esys.tsukuba.ac.jp m.kourogi@aist.go.jp, grof@hitl.washington.edu 
The Wearable Active Camera/Laser (WACL) allows the remote collaborators not only to set their viewpoints into the wearers workplace independent of the wearers motion but also to point to real objects directly with the laser spot. In this paper, we report an user test to examine the advantages and limitations of the WACL interface in remote collaboration by comparing a headmounted display and a headmounted camerabased headset interface. Results show that the WACL gives better impressions on comfortability when wearing, eyefriendliness, and fatigue in spite of no significant difference in task completion time. We first review related works and user studies with wearable collaborative systems, and then describe the details on the user test. 
In recent years computing and communication technologies have expanded from the desktop onto the body. Wearable computers [1] and wireless networking now allows us to develop portable conferencing and collaborative systems (e.g. [8, 20]). Wearable collaborative systems are significantly different than traditional desktop conferencing interfaces. For example, unlike most videoconferencing systems, the focus with wearable systems is usually on the real world task space. 
In a wearable interface it is often more beneficial that users can share views of the real world around them and what theyre doing, rather than images of their face [19]. They are also typically used in situations where the user wants to move around the task space rather than stay fixed in one place. Overall, since interaction with physical objects is essential in doing such real world tasks, the user does not want to be distracted by the interface of a wearable computer itself, and so the collaborative interface needs to be as easy to use as possible. 
A typical wearable system for remote collaboration comprises a headmounted display (HMD) and a headmounted camera (HMC) connected to a bodyworn computer and wireless link to a remote collaborator [8]. Audio and video images are sent to the remote collaborator to provide situational awareness of the users task space. In the HMD, the user can see the shared imagery on which the remote collaborator writes or draws annotations and other visual cues to support the users task [4]. 
In this paper we present a wearable interface for remote collaboration that does not use an HMD and the other headworn devices. We have recently developed a Wearable Active Camera/Laser (WACL) system [21] that involves wearing a steerable camera/laser head. The WACL interface allows the remote collaborators not only to independently set their viewpoint into the wearers task space such as a wearable robot developed by Mayol et al. [17], but also to point to real objects in the task space with the laser spot. 
In the remainder of this paper we first review related works and user studies with wearable collaborative systems, and then describe an experiment conducted to compare collaboration with the WACL interface to a more traditional headworn interface. Finally we outline directions for future work. 
The goal of collaborative interfaces is to enable remote users to establish shared understanding, or common ground in a process known as grounding [5]. One of the challenges of developing a wearable collaborative system is being able to provide the communication cues necessary for effective grounding. 
In facetoface collaboration, a wide variety of communication cues are used for establishing common ground, including gaze, face expression, gesture, speech and nonspeech audio. Many of these cues can be effectively con
veyed with traditional teleconferencing systems. In addition to verbal and nonverbal cues, real objects and interactions with the real world can also play an important role in facetoface collaboration. For example, Suchman found that drawing activities could be used to facilitate turn taking in much the same way that other nonverbal conversational cues do [22], while Mehan and Wood report that people use the resources of the real world to establish shared understanding [18]. 
In contrast to many traditional desktop collaboration interfaces with talking head video images, wearable collaborative systems are often designed to support users engaged in object manipulation tasks. In these systems it is most important to provide tools that facilitate effective situational awareness for the remote user and allow them to enhance interaction with the users surrounding environment. One of the first was work by Kuzuoka [14] in which a user wore an HMD and HMC and send images of his workspace back to a remote expert. Although not using a bodyworn computer, this demonstrated how an HMD could be used to enhance collaboration on a 3D spatial task. The expert could use his finger to indicate regions of interest in the video and the composite image of the finger on the remote video was shown back in the HMD. In this way nonverbal cues could be transmitted in both directions between collaborators. Kuzuoka found similar communication patterns in both the facetoface and remote cases, showing that video of the experts hand was effective at conveying remote pointing gestures. 
The CamNet system developed by British Telecom [3] was a similar system that allowed a medic to collaborate with a remote doctor using an HMD with attached camera. The doctor was able to use a mouse to point to portions of medical images that were shown in the HMD, while viewing video from the accident sight. This work showed that being able to share voice, imagery and a shared pointer may be sufficient for many remote collaboration tasks. 
Kraut et al. have conducted communication studies using a similar interface [12]. In this case a remote expert was helping a novice in a bicycle repair task. The novice wore an HMD and HMC and was able to see a shared desktop with an electronic manual with a live video view of the remote experts face. Kraut compared performance with and without the remote expert and also with and without video of the task space when the remote expert was present. Using the remote experts help, users were able to complete the task 50% faster. However the performance time was not affected by the presence or absence of video of the task space. Communication patterns did differ sharply between audio only, and audio and video conditions. Users were more explicit in describing the state of the task when they could not see each other, so Kraut et. al. report that the technology that the collaborators have available to them affects the manner 
remote experts situational awareness is provided by an HMC. However in this case the experts field of view is limited to what the user is looking at. Fussell et. al. [6] highlighted this problem by comparing remote collaboration using an HMC to that with a scene camera providing a fixed view of the workspace. They found that for remote collaboration in a fixed workspace, a wide angle scene camera may be preferable over an HMC. This is not surprising as a camera that enables the remote expert to see the entire workspace at once significantly increases situational awareness. 
These results show that remote collaboration is aided by providing a view of the task space, a means of remote pointing, and an interface that gives the remote expert the best situational awareness possible. 
As an alternative to HMD based systems, there have been a number of interfaces that present ways of projecting virtual information directly onto the objects themselves. For example, in Kuzuokas GestureCam interface [15] a small laser is mounted onto a servocontrolled camera that can be panned and tilted about. A remote expert can use this laser to highlight objects of interest. The WACL is similar to the GestureCam with the important difference that it is designed to be worn on the body and is fully portable so that the user can move around the task space. Mann has a related interface that uses a bodyworn steerable laser pointer and fixed camera to enable remote collaboration [16]. 
Using video projectors, virtual imagery as well as a pointer can be cast on real objects (e.g. [9, 10], Inami2000vr). In such projectorbased works, a wearable Mixed Reality (MR) projector system that Karitsuka and Sato proposed [11] is especially relevant to our WACL system in terms of projecting visual assistance in the real world with wearable devices and eliminating the users burden by wearing headworn devices although they have not yet developed remote collaboration applications. Along with the other projectorbased system, the system has several problems on the weight, power consumption, and luminance for outdoors use. 
In the user study described here, we compared remote collaboration with the WACL interface to that with a headset interface comprising an HMD and HMC. As the scenario for the user study, we are interested in collaboration between a mobile fieldworker and a remote expert. For example, a network engineer who has to move between multiple locations while getting directions from a remote supervisor. This type of scenario has previously been explored by a number of researchers using headworn systems (e.g.
Figure 2. Software interfaces that experts used for headset workers (left) and WACL workers (right). 
[2, 7]), but until now there has been no comparison between these systems and a wearable active camera/laser system like the WACL. The goal of this user study was to measure how different these conditions were in terms of task completion time, ease of use, communication behavior, and user preference. 
There are a number of important differences between a headset interface and the WACL interface. In a headset interface the remote expert sees a video feed from the fieldworkers HMC and so in a sense the expert can see through the eyes of the workers. In contrast, in the WACL interface the remote expert has independent control of its camera view. Also in the WACL interface the laser spot is shown on the real objects while in a video seethrough HMD system annotations appear on video on the real world. Thus we hypothesize that the remote controlled camera will allow the remote expert to have a better situational awareness, and that the laser spot will allow the fieldworker to remain focused on the task space rather than having to look at a video of the task space in the HMD. 
We have developed a Wearable Active Camera/Laser (WACL, size: 52 46 45 mm, weight: 100 g) attached around a shoulder as a hands, eye, and headfree wearable interface (Figure 1right) [21]. A small camera (270,000 
pixel 1/4inch color CCD, field of view: 49 degrees) and laser pointer (650nm, class 2) are mounted together on a pair of small DC geared motors controlled by a H8 microcontroller that enables them to pan and tilt (max: 270 and 82 degrees, respectively). 
As stated above, the remote expert can observe and pointing at targets in the real workplace around the fieldworker by controlling the WACL through wireless network. In addition, stabilization function based both on image registration and on a motion sensor (InterSense InterTrax2) attached to the WACL makes the direction of the camera/laser head stable on some level even if the wearer changes its posture. However, the visual assistance with the laser spot of the WACL is inferior to the HMD that has the capability to represent video images. The accuracy and spatial resolution of pointing is also not enough because of the miniaturized mechanism. 
As shown in Figures 1 (right), 3 (left), the fieldworkers wear the WACL, motion sensor, microphone, headphone, and subnotebook computer (PentiumM 1 GHz) in the backpack (total weight: about 2 kg). The video images (Motion JPEG, 320 240, 15 Hz) taken by the WACL, the sound (16 bit, 48 kHz) along with the pan/tilt angles of the WACL are transmitted to a remote PC through the WiFi (Figure 3). 
On the remote PC there is a software interface to communicate with the fieldworker as shown in Figure 2 (right). When the expert clicks with the left mouse button in the live video image (upper left of the GUI), the camera/laser head moves to center the view and the laser spot on that point. In addition our software creates pseudo panoramic views from images and the pan/tilt angles corresponding to the images so as to give the remote expert better situational awareness. As in the live video image, the expert can click in the panoramic image to change the pan/tilt angles of the
WACL, which makes it easier to rotate the WACL widely than in the live video image. The laser spot is toggled on and off with right click. 
When clicking with the middle mouse button, the stabilization function is activated. At the same time, the still image (objective image) is shown at the upperright side of the GUI so that the expert can confirm the target for stabilization1. In this way, the remote expert can see into the workers environment and indicate objects by providing remote pointing cues with the laser pointer. 
In addition to developing the WACL interface we also built a more traditional HMD/HMCbased headset system (Figures 1left, 4left). This consists of a monocular HMD (MicroOptical SV6) with the same camera as the WACL has. The HMD provides 640 480, 18 bit color resolution with 20 degree diagonal field of view, and can be used for left and right eye viewing. We used a transparent goggle as the headset frame in order to deal with whether or not each subject wears eyeglasses and to fix the HMD and HMC as stably as possible. 
The camera images are shown in the HMD with enhancements (pointer and line drawing) provided by the remote expert. In addition to the headset, the fieldworkers wear a microphone, headphone, and subnotebook computer in the backpack (total weight: about 2 kg). As with the WACL interface, the video images, the sound along with the other data including x/y coordinates of the mouse pointer are transmitted to a remote PC through the WiFi (Figure 4). 
Figure 2 (left) shows a software interface to communicate with the headset user. When the expert clicks with the middle mouse button in the live video image at the upper left of the GUI, the still image is displayed at the upperright side of the GUI. The image on which the expert puts the mouse pointer is shown in the workers HMD. In other words, the expert can easily select those images just by moving the pointer. While the expert holds the middle button down, the trajectory of the mouse pointer remains as line drawing in both the live and still image. As in the WACL, the mouse pointer is toggled on and off with right click. Through the interaction with the expert using the GUI, the fieldworker can listen to the experts voice while looking at either of the live video image or still image, pointer movement, and line drawing on the image. 
1In this study we used only sensorbased stabilization since drastic scene change was supposed to occur and it might cause imagebased stabilization not to work correctly. 
We chose a task that contained many of the elements of a remote collaboration task that are commonly seen across a variety of application domains, such as moving between different workspaces, interacting with objects in the real world, and receiving remote instruction. We had subjects undergo a Lego block building task at an experimental workplace which contains four sections, that is, sections A, B, C, and HOME (see Figure 5). Dozens of block clusters assembled with several blocks were distributed in sections A, B, and C, and a 67 cm long base block was put at HOME. The experts were in separate room to communicate with the workers only through wireless network. 
Under guidance from the remote expert, the worker had to do the following tasks at each of the sections. 
Section A Select two block clusters out of the 12, which is subject to the experts instruction. Each block cluster consists of green and yellow blocks and has a different shape from the others. 
Section B Select two block clusters out of the 12, which is subject to the experts instruction. Each block cluster has the same shape, but consists of several different colors. 
Section C (1a) Let the expert keep looking at a computer screen, (1b) Assemble 8 simple block shapes, and (2) Select a block cluster out of the 11. Even the expert does not know which block cluster should be selected until observing the computer screen for a while. Each block cluster has a different shape and consists of several different colors. 
Home Section Join two block clusters selected at each section out of the five to the required position on the base block and in the required direction by the expert.
On the computer monitor at section C, simple animation patterns that presented 0 or 1 were repeatedly indicated. By observing it for about 12 to 15 seconds, a code from 000 to 111 could be obtained and the expert got to know which block cluster should be selected. Meanwhile, the worker needed to do simple block assembly work and that made it difficult to keep looking at the computer screen. We chose this task which differentiates what the expert wants to see from what the fieldworker wants to see since such tasks are frequently seen in actual works, for example, checking monitors while keyboarding, and confirming some indicators and action of machines while connecting wires. At HOME section, relatively detailed instructions were needed to show the specific position and direction of block clusters to be on the base block. 
Each subject always started each trial with staying seated at HOME section and completed it with block assembly in a sitting position at HOME, and had to have a single visit to each section. In addition, subjects needed to return to HOME once on the way and put all block clusters, which were held at that time, on the table at HOME. For each trial we set up the order of visiting each section, the type of block clusters to be picked up, the code shown on the computer screen, and where on the base block and in which direction the worker should join each block cluster at random. To prevent the expert to observe everything at a glance with sufficient image resolution in each section, block clusters were spatially distributed. 
We conducted this user study with sixteen subjects (gender: seven female/ nine male, age: 24 to 38, height: 150 to 180 cm) as fieldworkers, of which two had experience of using an HMD in the past, and two were accustomed to wear and see it. Ten subjects were familiar with using computers, but six subjects were using computers less than 15 hours/week, which included three subjects using less than 8 hours/week. 
Two experts (male aged 24 and 33 years old) were paired with eight subjects each and gave instructions to each subject. Each pair did a trial for training and an actual trial with both the WACL and the headset. In order to prevent order effect, eight pairs started from the headset, and the rest eight pairs did the WACL first. In addition, each pair did one more trial to collect video data of both the workers field of view and the WACLs (experts) field of view simultaneously by wearing a HMC as well as the WACL, so each pair had five trials altogether. 
Each pair was notified to finish each trial as fast and correctly as possible, but not to run while moving between sections to prevent any accident. All subjects received $5 token gifts and were explained that subjects who had the fastest 
Figure 6. Total completion times for each trial. This boxandwhiskers plot shows the median, quartiles, and outlier and extreme values. 
Figure 7. Completion times at each section of the actual trials with the headset and that with the WACL. 
completion time with the WACL and the headset respectively could receive a $20 bonus. As for the experts, in order to saturate the learning effect, they did trials repetitively including the pilot tests. 
We present the results in two parts. First, we examine task completion time, and then examine questionnaire results that include ratings on ease of use, communication behavior, and user preference. 
Figure 6 shows a boxandwhiskers plot of total completion times of five trials. In this figure, each index on the vertical axis respectively shows training and actual trials with the headset, training and actual trials with the WACL,
and a trial to collect video data on the workers and the WACLs field of view. The last completion time (WACL &amp; HMC) is shown as a reference to indicate that the learning effect was fairly saturated. Using the Wilcoxon signed rank test, we found no significant difference between the actual task with the headset and with the WACL (p = 0.5). As described later, there are sections suitable for the headset and the WACL respectively, and it would appear that those time differences balanced each other out. This result did not change regardless of gender, which expert made instructions, experience on computers and HMDs, and no significant correlation was found between the completion time and height of each subject. 
As for the actual trials with the headset and that with the WACL, we measured sectional completion times of sections A, B, C and HOME, and the move among those sections (MOVE in Figure 7). Using the Wilcoxon signed rank test, we found a significant difference in completion time at section C between the headset and WACL (p = 0.007), but not at the other sections (A: p = 0.21, B: p = 0.48, HOME: p = 0.12, MOVE: p = 0.38). 
After all trials, all subjects (fieldworkers) were asked to absolutely and relatively rate impressions, ease of use, the users burden, and user preference of both the headset and the WACL by questionnaire and the followup interviews. First we compared the results of absolute rating using the Wilcoxon signed rank test (Figure 8), and found no significant difference in rating on Was the instructions with the device clear? (p = 0.43) and Could you easily send the remote expert for confirmation and such? (p = 1.0). 
We also found statistically no significant difference in ratings on Was it easy to see visual assistance (headset: image, mouse pointer, and line drawing, WACL: laser spot)? (p = 0.13) and Was it easy to make correspondence between the visual assistance and blocks or places in the real workplace? (p = 0.11), however as can be seen in Figure 8, there was a tendency that the WACL was rated higher than the headset in either case. Moreover, the WACL was rated significantly higher than the headset on Was there any uncomfortable feeling by wearing the device? (p = 0.002) and Was it easy to see the real workplace? (p = 0.003). 
Finally, Figure 9 shows relative ratings between the headset and the WACL. Using a onesample ttest (test value: 4), we found a significant deviation in a rating on Which device made you tired more when you did the trial? (p = 0.016), that is, using the headset made many subjects feel more tired rather than the WACL. However, there is no significant deviation in the other ratings which are on Which device did you feel that you could adapt 
yourself to faster through training? (p = 0.173), With which device was it easy to do the task? (p = 0.787), Which device made you feel the presence of the expert more? (p = 0.304), and With which device did you finish the task faster? (p = 1.0). 
In summary, this user test has shown that the WACL gives better impressions on comfortability when wearing, eyefriendliness, and fatigue in spite of no significant difference in total completion times between the headset and the WACL. We had comments from several subjects about the headset associated with the impression as follows: I was mixedup about what I should see, that is, the image on the headset or the real workplace, I felt weary in eyes and brains with the headset, I often had difficulties in focusing my attention on the tasks since it made me nervous that the headset was getting out of the position when I was moving, and I was bothered by a feeling of strangeness
Figure 10. An example of keeping observing the computer monitor with the sensorbased stabilization of the WACL (This video data were recorded in a WACL &amp; HMC trial). The right most figures shows that the expert was looking for the block cluster when the worker was still assembling blocks. Upper: the WACLs (experts) field of view, Lower: the workers field of view. 
more strongly when wearing the headset. The first two issues may be solved by virtual retinal displays to some extent, however, the latter two issues are inevitably involved by any headworn devices. It cannot be denied that completion times and impressions of each condition are subject to how to set up tasks and how complicated communication we need. However, this result has shown us the potential ability of the WACL in remote collaboration. 
As for sectional completion times, pairs with the WACL performed the task at section C significantly faster than with the headset. At the section, it was highly difficult for the fieldworkers to do block assembly work and to keep looking at the computer screen simultaneously, and that forced all pairs with the headset to do either of them first. In contrast, the WACL allowed the experts to keep observing the screen while the workers were assembling blocks by controlling the WACL despite the workers posture change. Almost all workers often rocked backward and forward and twisted their body at the waist, nevertheless, the experts were able to keep observing the screen by activating the sensorbased stabilization. Moreover, in some trials, the expert was able to complete observing the screen and to start looking for the block cluster when the worker was still assembling blocks (Figure 10). This example has shown that the viewcontrollability of the WACL is advantageous even when the worker and the expert see the almost same place while gazing at different targets. 
At the other sessions, we found no significant difference in completion time, but as can be seen in Figure 7, there was a tendency that pairs with the headset performed faster than with the WACL at sections HOME and A. At HOME section, the experts needed to explain the details about the place and the direction of block clusters to put them on the base block, but since line drawing was available with the HMD, the detailed verbal instructions were hardly necessary. On the other hand, the expert communicating with the 
worker with the WACL often had to redo pointing operations due to displacement of the laser spot from the target along with slight movement of the workers body2 as well as due to inadequate positioning accuracy of the pan/tilt angles. That required detailed verbal instructions when the expert gave instructions about the position of studs on the base block used to join block clusters (e.g. the third stud on the right back side from the corner that the laser is pointing at instead of just here with the headset). In addition, detailed verbal instructions were required since it was difficult to explain how to rotate each block cluster to put. It would appear that these factors made some tendency that the headset trial performed faster than the WACL at HOME section. Many subjects commented on this, that it was easy to join block clusters on the base block with the headset owing to the line drawing on the still image. Both of two experts also felt that the headset was fairly easier to give instructions, even though the WACL was easier to observe the remote workplace [13]. 
Tasks themselves at sections A and B were the same, that is, to pick up two block clusters, but there were two differences between them, which were, on the placement of block clusters (A: distributed on two places of which the height differed from each other, B: distributed uniformly on the floor) and on visual cues to find the block clusters (A: different shapes, B: different combinations of colors). As described the above, there were no significant difference in completion time between the headset and the WACL at those two sections, but at section A, there was a tendency that pairs with the headset performed faster than with the WACL and the variance with the headset was smaller. The resolution of targets on images is required to be higher for identifying the shape rather than for identifying the color. With the headset, the worker was able to easily show the expert each block cluster one after another in a positive way while confirming how the block clusters showed up in the image with the HMD. However, the worker with the WACL had no means of confirming the appearance of the targets, and that made each worker relatively passive. The following comments has represented these factors very well; Since the distance between the camera (WACL) and targets varied widely along with sections, I was worried about how large the expert had been looking at targets., I got tired since I had to keep moving the camera (headset) so that the expert could see targets adequately. 
In this study we examined the advantages and limitations to be improved that the WACL interface has by comparing with the HMD/HMCbased headset interface, and presented 
the potential ability of the WACL in remote collaboration. It is possible to improve positioning accuracy of the pan/tilt angles and stabilization response of the WACL, however in practice, eliminating displacement of the laser spot from the target along with movement of the wearer is an open problem as in registration problems in the optical seethrough HMDs. One of the possible means to compensate for the registration problem is to equip the WACL user with an additional display device for presenting detailed visual assistance. A ShoulderWorn Display (SWD) [21] may be suitable for this purpose since the SWD does not spoil the advantages of the WACL which is hands, eye, and headfree interface. In the future, we plan to develop a new WACLbased interface with the SWD and carry out another user test to assess how it works compared with the WACLonly case. 
In addition, We have not fully addressed the difference especially in communication behavior yet. We will analyze transcripts of video log data collected in this study to clarify how communication patterns differ between each interface and communication asymmetries [2]. 
ACKNOWLEDGEMENTS: This work is supported in part by Special Coordination Funds for Promoting Science and Technology from MEXT and by JSPS Postdoctoral Fellowships for Research Abroad (H15). 
[2] M. Billinghurst, S. Bee, J. Bowskill, and H. Kato. Asymmetries in collaborative wearable interfaces. In Proc. ISWC99, pages 133140, 1999. 
[4] L. Cheng and J. Robinson. Dealing with speed and robustness issues for videobased registration on a wearable computing platform. In Proc. ISWC98, pages 8491, 1998. 
[5] H. H. Clark and S. E. Brennan. Perspectives on socially shared cognition, chapter Grounding in communication, pages 127149. APA Books, Washington, DC, 1991. 
[6] S. R. Fusell, L. D. Setlock, and R. E. Kraut. Effects of headmounted and sceneoriented video systems on remote collaboration on physical tasks. In Proc. CHI 2003, pages 513 520, 2003. 
[7] D. Gobert. Designing wearable performance support: Insights from the early literature. Technical COMMUNICATION, 49(4):444448, 2002. 
[8] B. Hestnes, S. Heiestad, P. Brooks, and L. Drageset. Real situations of wearable computers used for video conferencingand implications for terminal and network design. In Proc. ISWC2001, pages 8593, 2001. 
[9] S. Hiura, K. Tojo, and S. Inokuchi. 3d teledirection interface using video projector. In SIGGRAPH 2003, CDROM/DVDROM, 2003. 
[10] H. Hua, A. Girardot, C. Gao, and J. Rolland. Engineering of headmounted projective displays. Applied Optics, 39(22):38143824, 2000. 
[11] T. Karitsuka and K. Sato. A wearable mixed reality with an onboard projector. In Proc. ISMAR 2003, pages 321322, 2003. 
[12] R. E. Kraut, M. D. Miller, and J. Siegal. Collaboration in performance of physical tasks: Effects on outcomes and communication. In Proc. CSCW 96, pages 5766, 1996. 
[13] T. Kurata, N. Sakata, M. Kourogi, H. Kuzuoka, and M. Billinghurst. The advantages and limitations of a wearable active camera/laser in remote collaboration. In Interactive Poster at CSCW 2004, 2004. 
[14] H. Kuzuoka. Spatial workpace collaboration: A sharedview video support system for remote collaboration capability. In Proc. CHI 92, pages 533540, 1992. 
[15] H. Kuzuoka, T. Kosuge, and M. Tanaka. Gesturecam: A video communication system for sympathetic remote collaboration. In Proc. CSCW 94, pages 3543, 1994. 
[16] S. Mann. Telepointer: Handsfree completely self contained wearable visual augmented reality without headwear and without any infrastructure reliance. In Proc. ISWC00, pages 177178, 2000. 
[17] W. Mayol, B. Tordoff, and D. Murray. Wearable visual robots. In Proc. ISWC2000, pages 95102, 2000. 
[19] B. Nardi, H. Schwarz, A. Kuchinsky, R. Leichner, S. Whittaker, and R. Sclabassi. Turning away from talking heads: The use of videoasdata in neurosurgery. In Proc. INTERCHI93, pages 327334, 1993. 
[20] M. Okada, A. Yamada, H. Tarumi, M. Yoshida, and K. Moriya. DigitalEE II: RVaugmented interface design for networked collaborative environmental learning. In Proc. International Conference on Computer Support for Collaborative Learning, pages 265274, 2003. 
[21] N. Sakata, T. Kurata, T. Kato, M. Kourogi, and H. Kuzuoka. WACL: Supporting telecommunications using wearable active camera with laser pointer. In ISWC 2003, pages 5356, 2003. 
[22] L. Suchman. Representation in scientific practice, chapter Representing practice in cognitive science, pages 301321. MIT Press, Cambridge, MA, 1990.
&lt;&lt; /ASCII85EncodePages false /AllowTransparency false /AutoPositionEPSFiles true /AutoRotatePages /All /Binding /Left /CalGrayProfile (Dot Gain 20%) /CalRGBProfile (sRGB IEC619662.1) /CalCMYKProfile (U.S. Web Coated \050SWOP\051 v2) /sRGBProfile (sRGB IEC619662.1) /CannotEmbedFontPolicy /Warning /CompatibilityLevel 1.4 /CompressObjects /Tags /CompressPages true /ConvertImagesToIndexed true /PassThroughJPEGImages true /CreateJDFFile false /CreateJobTicket false /DefaultRenderingIntent /Default /DetectBlends true /ColorConversionStrategy /LeaveColorUnchanged /DoThumbnails false /EmbedAllFonts true /EmbedJobOptions true /DSCReportingLevel 0 /SyntheticBoldness 1.00 /EmitDSCWarnings false /EndPage1 /ImageMemory 1048576 /LockDistillerParams false /MaxSubsetPct 100 /Optimize true /OPM 1 /ParseDSCComments true /ParseDSCCommentsForDocInfo true /PreserveCopyPage true /PreserveEPSInfo true /PreserveHalftoneInfo false /PreserveOPIComments false /PreserveOverprintSettings true /StartPage 1 /SubsetFonts true /TransferFunctionInfo /Apply /UCRandBGInfo /Preserve /UsePrologue false /ColorSettingsFile () /AlwaysEmbed [ true ] /NeverEmbed [ true ] /AntiAliasColorImages false /DownsampleColorImages true /ColorImageDownsampleType /Bicubic /ColorImageResolution 300 /ColorImageDepth1 /ColorImageDownsampleThreshold 1.50000 /EncodeColorImages true /ColorImageFilter /DCTEncode /AutoFilterColorImages true /ColorImageAutoFilterStrategy /JPEG /ColorACSImageDict &lt;&lt; /QFactor 0.15 /HSamples [1 1 1 1] /VSamples [1 1 1 1] &gt;&gt; /ColorImageDict &lt;&lt; /QFactor 0.15 /HSamples [1 1 1 1] /VSamples [1 1 1 1] &gt;&gt; /JPEG2000ColorACSImageDict &lt;&lt; /TileWidth 256 /TileHeight 256 /Quality 30 &gt;&gt; /JPEG2000ColorImageDict &lt;&lt; /TileWidth 256 /TileHeight 256 /Quality 30 &gt;&gt; /AntiAliasGrayImages false /DownsampleGrayImages true /GrayImageDownsampleType /Bicubic /GrayImageResolution 300 /GrayImageDepth1 /GrayImageDownsampleThreshold 1.50000 /EncodeGrayImages true /GrayImageFilter /DCTEncode /AutoFilterGrayImages true /GrayImageAutoFilterStrategy /JPEG /GrayACSImageDict &lt;&lt; /QFactor 0.15 /HSamples [1 1 1 1] /VSamples [1 1 1 1] &gt;&gt; /GrayImageDict &lt;&lt; /QFactor 0.15 /HSamples [1 1 1 1] /VSamples [1 1 1 1] &gt;&gt; /JPEG2000GrayACSImageDict &lt;&lt; /TileWidth 256 /TileHeight 256 /Quality 30 &gt;&gt; /JPEG2000GrayImageDict &lt;&lt; /TileWidth 256 /TileHeight 256 /Quality 30 &gt;&gt; /AntiAliasMonoImages false /DownsampleMonoImages true /MonoImageDownsampleType /Bicubic /MonoImageResolution 1200 /MonoImageDepth1 /MonoImageDownsampleThreshold 1.50000 /EncodeMonoImages true /MonoImageFilter /CCITTFaxEncode /MonoImageDict &lt;&lt; /K1 &gt;&gt; /AllowPSXObjects false /PDFX1aCheck false /PDFX3Check false /PDFXCompliantPDFOnly false /PDFXNoTrimBoxError true /PDFXTrimBoxToMediaBoxOffset [ 0.00000 0.00000 0.00000 0.00000 ] /PDFXSetBleedBoxToMediaBox true /PDFXBleedBoxToTrimBoxOffset [ 0.00000 0.00000 0.00000 0.00000 ] /PDFXOutputIntentProfile () /PDFXOutputCondition () /PDFXRegistryName (http://www.color.org) /PDFXTrapped /Unknown /Description &lt;&lt; /FRA &lt;FEFF004f007000740069006f006e00730020007000650072006d0065007400740061006e007400200064006500200063007200e900650072002000640065007300200064006f00630075006d0065006e00740073002000500044004600200064006f007400e900730020006400270075006e00650020007200e90073006f006c007500740069006f006e002000e9006c0065007600e9006500200070006f0075007200200075006e00650020007100750061006c0069007400e90020006400270069006d007000720065007300730069006f006e00200061006d00e9006c0069006f007200e90065002e00200049006c002000650073007400200070006f0073007300690062006c0065002000640027006f00750076007200690072002000630065007300200064006f00630075006d0065006e007400730020005000440046002000640061006e00730020004100630072006f0062006100740020006500740020005200650061006400650072002c002000760065007200730069006f006e002000200035002e00300020006f007500200075006c007400e9007200690065007500720065002e&gt; /ENU (Use these settings to create PDF documents with higher image resolution for improved printing quality. The PDF documents can be opened with Acrobat and Reader 5.0 and later.) /JPN &lt;FEFF3053306e8a2d5b9a306f30019ad889e350cf5ea6753b50cf3092542b308000200050004400460020658766f830924f5c62103059308b3068304d306b4f7f75283057307e30593002537052376642306e753b8cea3092670059279650306b4fdd306430533068304c3067304d307e305930023053306e8a2d5b9a30674f5c62103057305f00200050004400460020658766f8306f0020004100630072006f0062006100740020304a30883073002000520065006100640065007200200035002e003000204ee5964d30678868793a3067304d307e30593002&gt; /DEU &lt;FEFF00560065007200770065006e00640065006e0020005300690065002000640069006500730065002000450069006e007300740065006c006c0075006e00670065006e0020007a0075006d002000450072007300740065006c006c0065006e00200076006f006e0020005000440046002d0044006f006b0075006d0065006e00740065006e0020006d00690074002000650069006e006500720020006800f60068006500720065006e002000420069006c0064006100750066006c00f600730075006e0067002c00200075006d002000650069006e0065002000760065007200620065007300730065007200740065002000420069006c0064007100750061006c0069007400e400740020007a0075002000650072007a00690065006c0065006e002e00200044006900650020005000440046002d0044006f006b0075006d0065006e007400650020006b00f6006e006e0065006e0020006d006900740020004100630072006f0062006100740020006f0064006500720020006d00690074002000640065006d002000520065006100640065007200200035002e003000200075006e00640020006800f600680065007200200067006500f600660066006e00650074002000770065007200640065006e002e&gt; /PTB &lt;FEFF005500740069006c0069007a006500200065007300740061007300200063006f006e00660069006700750072006100e700f5006500730020007000610072006100200063007200690061007200200064006f00630075006d0065006e0074006f0073002000500044004600200063006f006d00200075006d00610020007200650073006f006c007500e700e3006f00200064006500200069006d006100670065006d0020007300750070006500720069006f0072002000700061007200610020006f006200740065007200200075006d00610020007100750061006c0069006400610064006500200064006500200069006d0070007200650073007300e3006f0020006d0065006c0068006f0072002e0020004f007300200064006f00630075006d0065006e0074006f0073002000500044004600200070006f00640065006d0020007300650072002000610062006500720074006f007300200063006f006d0020006f0020004100630072006f006200610074002c002000520065006100640065007200200035002e0030002000650020007300750070006500720069006f0072002e&gt; /DAN &lt;FEFF004200720075006700200064006900730073006500200069006e0064007300740069006c006c0069006e006700650072002000740069006c0020006100740020006f0070007200650074007400650020005000440046002d0064006f006b0075006d0065006e0074006500720020006d006500640020006800f8006a006500720065002000620069006c006c00650064006f0070006c00f80073006e0069006e006700200066006f00720020006100740020006600e50020006200650064007200650020007500640073006b00720069006600740073006b00760061006c0069007400650074002e0020005000440046002d0064006f006b0075006d0065006e0074006500720020006b0061006e002000e50062006e006500730020006d006500640020004100630072006f0062006100740020006f0067002000520065006100640065007200200035002e00300020006f00670020006e0079006500720065002e&gt; /NLD &lt;FEFF004700650062007200750069006b002000640065007a006500200069006e007300740065006c006c0069006e00670065006e0020006f006d0020005000440046002d0064006f00630075006d0065006e00740065006e0020007400650020006d0061006b0065006e0020006d00650074002000650065006e00200068006f0067006500720065002000610066006200650065006c00640069006e00670073007200650073006f006c007500740069006500200076006f006f0072002000650065006e0020006200650074006500720065002000610066006400720075006b006b00770061006c00690074006500690074002e0020004400650020005000440046002d0064006f00630075006d0065006e00740065006e0020006b0075006e006e0065006e00200077006f007200640065006e002000670065006f00700065006e00640020006d006500740020004100630072006f00620061007400200065006e002000520065006100640065007200200035002e003000200065006e00200068006f006700650072002e&gt; /ESP &lt;FEFF0055007300650020006500730074006100730020006f007000630069006f006e006500730020007000610072006100200063007200650061007200200064006f00630075006d0065006e0074006f0073002000500044004600200063006f006e0020006d00610079006f00720020007200650073006f006c00750063006900f3006e00200064006500200069006d006100670065006e00200070006100720061002000610075006d0065006e0074006100720020006c0061002000630061006c006900640061006400200061006c00200069006d007000720069006d00690072002e0020004c006f007300200064006f00630075006d0065006e0074006f00730020005000440046002000730065002000700075006500640065006e00200061006200720069007200200063006f006e0020004100630072006f00620061007400200079002000520065006100640065007200200035002e003000200079002000760065007200730069006f006e0065007300200070006f00730074006500720069006f007200650073002e&gt; /SUO &lt;FEFF004e00e4006900640065006e002000610073006500740075007300740065006e0020006100760075006c006c006100200076006f0069006400610061006e0020006c0075006f006400610020005000440046002d0061007300690061006b00690072006a006f006a0061002c0020006a006f006900640065006e002000740075006c006f0073007400750073006c00610061007400750020006f006e0020006b006f0072006b006500610020006a00610020006b007500760061006e0020007400610072006b006b007500750073002000730075007500720069002e0020005000440046002d0061007300690061006b00690072006a0061007400200076006f0069006400610061006e0020006100760061007400610020004100630072006f006200610074002d0020006a00610020004100630072006f006200610074002000520065006100640065007200200035002e00300020002d006f0068006a0065006c006d0061006c006c0061002000740061006900200075007500640065006d006d0061006c006c0061002000760065007200730069006f006c006c0061002e&gt; /ITA &lt;FEFF00550073006100720065002000710075006500730074006500200069006d0070006f007300740061007a0069006f006e00690020007000650072002000630072006500610072006500200064006f00630075006d0065006e00740069002000500044004600200063006f006e00200075006e00610020007200690073006f006c0075007a0069006f006e00650020006d0061006700670069006f00720065002000700065007200200075006e00610020007100750061006c0069007400e00020006400690020007300740061006d007000610020006d00690067006c0069006f00720065002e0020004900200064006f00630075006d0065006e00740069002000500044004600200070006f00730073006f006e006f0020006500730073006500720065002000610070006500720074006900200063006f006e0020004100630072006f00620061007400200065002000520065006100640065007200200035002e003000200065002000760065007200730069006f006e006900200073007500630063006500730073006900760065002e&gt; /NOR &lt;FEFF004200720075006b00200064006900730073006500200069006e006e007300740069006c006c0069006e00670065006e0065002000740069006c002000e50020006f00700070007200650074007400650020005000440046002d0064006f006b0075006d0065006e0074006500720020006d006500640020006800f80079006500720065002000620069006c00640065006f00700070006c00f80073006e0069006e006700200066006f00720020006200650064007200650020007500740073006b00720069006600740073006b00760061006c0069007400650074002e0020005000440046002d0064006f006b0075006d0065006e00740065006e00650020006b0061006e002000e50070006e006500730020006d006500640020004100630072006f0062006100740020006f0067002000520065006100640065007200200035002e00300020006f0067002000730065006e006500720065002e&gt; /SVE &lt;FEFF0041006e007600e4006e00640020006400650020006800e4007200200069006e0073007400e4006c006c006e0069006e006700610072006e00610020006e00e40072002000640075002000760069006c006c00200073006b0061007000610020005000440046002d0064006f006b0075006d0065006e00740020006d006500640020006800f6006700720065002000620069006c0064007500700070006c00f60073006e0069006e00670020006f006300680020006400e40072006d006500640020006600e50020006200e400740074007200650020007500740073006b00720069006600740073006b00760061006c0069007400650074002e0020005000440046002d0064006f006b0075006d0065006e00740065006e0020006b0061006e002000f600700070006e006100730020006d006500640020004100630072006f0062006100740020006f00630068002000520065006100640065007200200035002e003000200065006c006c00650072002000730065006e006100720065002e&gt; /KOR &lt;FEFFd5a5c0c1b41c0020c778c1c40020d488c9c8c7440020c5bbae300020c704d5740020ace0d574c0c1b3c4c7580020c774bbf8c9c0b97c0020c0acc6a9d558c5ec00200050004400460020bb38c11cb97c0020b9ccb4e4b824ba740020c7740020c124c815c7440020c0acc6a9d558c2edc2dcc624002e0020c7740020c124c815c7440020c0acc6a9d558c5ec0020b9ccb4e000200050004400460020bb38c11cb2940020004100630072006f0062006100740020bc0f002000520065006100640065007200200035002e00300020c774c0c1c5d0c11c0020c5f40020c2180020c788c2b5b2c8b2e4002e&gt; /CHS &lt;FEFF4f7f75288fd94e9b8bbe7f6e521b5efa76840020005000440046002065876863ff0c5c065305542b66f49ad8768456fe50cf52068fa87387ff0c4ee563d09ad8625353708d2891cf30028be5002000500044004600206587686353ef4ee54f7f752800200020004100630072006f00620061007400204e0e002000520065006100640065007200200035002e00300020548c66f49ad87248672c62535f003002&gt; /CHT &lt;FEFF4f7f752890194e9b8a2d5b9a5efa7acb76840020005000440046002065874ef65305542b8f039ad876845f7150cf89e367905ea6ff0c4fbf65bc63d066075217537054c18cea3002005000440046002065874ef653ef4ee54f7f75280020004100630072006f0062006100740020548c002000520065006100640065007200200035002e0030002053ca66f465b07248672c4f86958b555f3002&gt; &gt;&gt; &gt;&gt; setdistillerparams &lt;&lt; /HWResolution [2400 2400] /PageSize [612.000 792.000] &gt;&gt; setpagedevice 
