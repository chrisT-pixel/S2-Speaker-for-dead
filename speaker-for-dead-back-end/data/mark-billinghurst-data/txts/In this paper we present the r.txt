In this paper we present the results of our long term development of a mixed reality book. Most previous work in the area has focused on the technology of augmented reality books, such as providing registration using fiducial markers. In this work, however, we focused on exploring the design and development process of this type of application in a broader sense. We studied the semantics of a mixed reality book, the design space and the user experience with this type of interface. 
Index Terms: H.5.1 [Information interfaces and presentation]: Multimedia Information systemsArtificial, augmented, and virtual realities 
Recent progress in display technologies allows the development of electronic books offering better visual quality for reading. This continues a long line of advances aimed at enhancing the traditional printed book with electronic features: audio book, multimedia CD ROM book, online interactive book, electronic book readers, etc. 
In [14], Marshall et al. have shown that users still love the physicality of a real book which offer a broad range of advantages: transportability, flexibility, robustness, etc. These factors support research into another future for books: digitally augmenting and enhancing real books. This combines the advantages of physical books with new interaction possibilities offered by digital media. 
One pathway to create new types of visually enhanced books is the use of Augmented Reality (AR). As an example Billinghurst et al. proposed the MagicBook in 2001 [3]. Their prototype introduced various general contributions, but the essence was the concept of an augmented reality book containing 3D virtual and animated content registered on real pages, mimicking a traditional popup book. Since then there have been a succession of similar works in this area, mainly dominated by application demonstrations (architectural AR books, medical AR books, etc.) or technology related contributions (markerbased versus markerless tracking, projected versus video seethrough, etc.). Despite this, there has been little research on how to design such books. Fundamental questions have rarely been raised, such as the proper definition of an augmented book, the categorization of these books, the design space, and the development process. 
The motivation of our work is to focus on these issues and to meticulously explore the design aspects of augmented books. To our knowledge no similar attempts have been made trying to define and understand visually augmented books in depth. We do this based on our past experiences in the area ([24], [15]), [6] and through the development of a new type of augmented book prototype. 
email:raphael.grasset@hitlabnz.org email:andreas.duenser@hitlabnz.org email:mark.billinghurst@hitlabnz.org 
In 2000 Harrison et al. [9] explored the future of reading and the development of digital books. A large part of the research on digital books focussed on studying usability (e.g. reading on screen), application areas (e.g. education) or the development of new interaction techniques. Work such as [18] shows the importance of annotation, ease of navigation and the layout of information. Recently Chen et al. [5] introduced new navigation techniques for electronic readers, reproducing physical metaphors used in interaction with a real book. 
Card et al. [4], have proposed to physically simulate the behaviour of a real book in the presentation of a 3D virtual book. They extended their prototype [10] to support virtual annotation or bookmarking. More recently, Welch et al. [23] extended the concept further to an immersive Virtual Reality book aimed at medical training for surgery. 
Work on augmented paper and augmented books has explored the link between real and digital paper, the use of different interaction techniques and technologies, audio augmentation [2], and visual augmentation. For example [13] designed different prototypes of an augmented laboratory notebook combining a tabletPC and PDA, and Signer has studied the concept of interactive paper and demonstrated different examples of augmented books [19]. 
For visually augmented books, different projects have explored the application of the MagicBook concept in different areas: chemistry [1], biology [7], cultural heritage [22], gaming [11] to name but a few. In [17], the authors proposed the integration of a physical controller in an augmented reality book. Taketa et al. [20] discuss a new naturalfeaturetracking technology usable for augmented books. These latter works are generally technology focused, proposing new technological solutions for the MagicBook concept. 
However, few of these works attempt to develop a general conceptual model for development of similar books, or evaluate the developed prototyped with user studies, or comment on design issues and the overall user experience. In the next section we discuss the design approaches for developing augmented reality books and demonstrate how we applied these approaches in the development of a mixed reality book. 
A large part of our work over the years has been guided by the development of different custom augmented reality books: The Black Magic Book, AR Volcano book [24], Nanotech Book, CEBIT 2006 MagicBook, and Giant Jimmy Jones [15]. More recently we focused creating of a mixedreality book based on an already published book [8]. During our work we explored different areas including the underlying technology, the book content and the educational and entertainment values. We also studied various kinds of books in libraries ranging from preschool books and story books, through to science books and high school text books. We mainly analyzed the content of each book, the differences in structure, layout of information, and the potential to extend them with AR technology.
 3D content: static 3D models (objects, environment), dynamic models (animation, 3D video avatars). 
 Sound: ambient sound (music, background noise), spatial sound (3D sound depending on the user actions and location), interactive sounds. 
The developments of augmented books can be categorised in different ways. One is by the use of certain technologies such as embedded sensors inside the book, and the use of external devices to operate it, and the use of a special device to read it (MagicBook type approach). Another one is by the supported sensory modality such as audio augmentation, haptic augmentation or visual augmentation. 
We attempt to classify augmented books according to their physicality which parallels the Continuum of Object Meanings for tangible interfaces introduced by Underkoffler and Ishii [21] and the realityvirtuality continuum proposed by Milgram et al. [16]. Figure 1 shows the elements of our classification axis. 
The physicality of a book can be determined by how many physical elements are present, defining the real books affordances and content. A virtual book is a completely electronic format and thus has little physicality. In a traditional AR Book (or Virtual AR Book) a physical book generally is used as an interface (e.g. turning the page) augmented with virtual content. However, there is little physical relationship between the physical pages and its content and the virtual content. With a Mixed Reality Book we propose to combine and seamlessly merge physical and virtual content in more meaningful ways. 
We can categorize Virtual AR Books with respect to the layout of the content and the importance of real content in the book (see Figure 2) : 
The representation of content can be either real or virtual or a mixture of both. For example a representation of a car can have some parts drawn in a 2D illustration and some parts popping up in a 3D virtual model which provides the user with an integrated version. We will discuss this concept of spatially merging information and its benefits in the next section. 
In an augmented book we have planar or almost planar surfaces. Considering this, we identified three levels of tracking complexity: 
Different technologies can be used to obtain fast and robust tracking. We concentrated our efforts on using optically based tracking which is most appropriate for printed books. In this case, computer vision based tracking systems may require additional pictorial elements on the book pages which can interfere visually with the actual content, such as adding square ARToolKit [12] fiducial markers. The visibility of the tracking technology and its relationship to the original book images for the user can be grouped into (see Figure 3): 
 tracking visible in an area spatially separated from the book content (e.g. positioned on the page border). 
With a real book, the layout of information is generally limited to a 2D flat surface (although there are some limited options of 3D content with popup books). In the context of a mixedreality book, the pages of the book define the coordinate reference for positioning virtual objects in the space above them. 
The layout of these objects (2D, 3D, or 3D sound) can be defined by standard Euclidian and geometric characteristics (position, orientation, size, etc). A virtual tree, for example, can be placed parallel to the surface of the real page, vertically on the page, or even outside of the page. 
Figure 4: Different Layout of virtual elements related to real content. The drawing of a real house can be enhanced (adding virtual ground), replicated (having a 3D model of the house near the 2D representation), replaced (the 3D house becomes the only content visible to the user). 
However, we can define more precisely other relations between real and virtual content. Considering the scenario of a 2D drawing of a house on a page, how can this be enhanced with virtual content and what is the relation between the real house and the virtual added element? 
Figure 4 shows some layout examples: virtually enhancing parts of an object, replicating an object (two visual representations of the content) and replacing an object. 
In a similar way the distance between elements will impact on the sense of integration between them. Placing a virtual tree in contact with the page will create the illusion that the tree is on the page rather than having it floating above it. 
With a real book, the user can switch between pages by the physical action of turning the page. Certain popup books enhance the interaction by allowing the user to push, pull, roll, and press different interactive features present in the book (some with the addition of electronic sensors). In our design space, we want to replicate similar interaction techniques already existing in a real book. So we need to limit the use of cumbersome supplementary devices, or fixed devices that restrict the book mobility. 
Figure 5 shows the different interaction spaces. A user can interact with the content of the book, but can also bring something from outside of the book inside it. In a similar way, the user can grab something from inside the book and move it outside for another activity. For example, some puzzle books have pieces that can be removed from the book and are assembled on a table. Further refining the interaction with the inside of the book, there are two types of interaction: (1) interaction with the physical container, or (2) with the content of the book. As an example of the former, a user could tilt the page to control the gravity of some objects. For the latter, we isolated three major categories of interaction: (1) Gaze Interaction (looking at something to interact with the book content), (2) Finger Interaction (pointing or moving parts of your hands to interact with the book content), and (3) Tangible Interaction (positioning or moving a tangible element to interact with the content of the book). 
When we consider tangible interaction, the physical design of the interface (shape, size, dimensionality, see Figure 6) will influence the affordance, and therefore interaction with the content. 
 POSITIONING: Placing an element at a specific position by direct interaction. Examples include placing a tangible interface to start an animation, or arranging some virtual objects. 
 MOVING: Moving/Gesturing from one position to another or by doing a specific movement (direct interaction). Following our space design, the user can either insert elements into the book, or pick elements up from the book. Examples include moving a virtual character on a specific path on the page, carrying out a specific gesture to start an animation (e.g. slide, rotate, press). 
 CONTROLLING: Placing and moving an element to a specific position to control an interface value (indirect interaction). For example a virtual slider could change an object, or a virtual dial could control the liquid level in a physical simulation. 
The visual superimposing of real and virtual content creates questions about providing visual information to the user, and showing them where and how to interact. For instance, a user can click on an element of a real book to start a 3D virtual animation. However, how can this point of interaction be presented to the user? How can the user know where to interact, and moreover, should the guidance be presented using real or virtual information? 
Shown in Figure 7 we considered three types of possible solutions: (1) providing no visual guidance, (2) providing virtual visual feedback (hotspot), (3) providing a real physical element (hint). 
Providing a level of immersion and developing a reading experience with digital books has been a focus of lot of previous research. In the context of our work, we tried to understand how augmenting real content with virtual content can favor user immersion, and enhance the reading experience.
Transparency and Visibility of Technology: With a real book, the user experience is generally not disrupted by the technology present. In a mixedreality book the transparency of the technology should also be guaranteed. For a storytelling book, proper design of the physical interface can contribute to this. Examples are making tracking technology invisible or using a meaningful tangible interface to interact like a real object (e.g. an interface in the shape of a fishing rod for a fishing book). 
Visual Surround: being immersed in a book generally includes loosing ones sense of time, space and surroundings. The extra dimensionality provided by a Mixed Reality Book (i.e. 3D virtual elements) reproduces the experience of popup book. However, we can extend this further by not only augmenting the content of the book but also visually augmenting the surroundings, filling the users field of view. For example, a user reading a book about fish can see the area around the book augmented with a virtual sea. 
Other Media: we have also been inspired by techniques implemented in other digital media to enhance immersion with the book. The most appealing ones have been cinematographic effects. For this matter, we consider visual effects, either by animation (camera movement, and thus movement of objects between different spatial areas) or image processing effects (fading, blurring, etc). 
In this paper we discussed a design space for the development of mixed reality books and, more generally, visually augmented books. During our work we investigated different aspects of design elements for mixedreality books and attempted to categorize them. As technology gets more mature exploring design issues becomes more important. 
Different interaction techniques can be explored and studied in more detail to refine our design space. For example, people naturally use their fingers for interaction which could be integrated as direct gesture input. Integration of eyetracking into visualization devices will need to extend to gazebased interaction. 
Other concepts such as the transitional interface proposed by [3] can be integrated in such books. In addition, immersion, engagement and interactivity are major components to explore further with this type of technology. In the future, we plan to empirically compare real books, digital books and visually augmented books with respect to differences in these previous factors and usability. 
We also envision to explore other design components we havent described in this paper. For example, we are aiming to study authoring tools dedicated to visually augmented books. The development of augmented book prototypes still requires extensive time investments of very specialized experts. Therefore these books are generally oneoffs and the development times and costs hinder their wider distribution. Added to that, the modification of the standard publishing methods would be needed because of the integration different content types (e.g. auditory content, 3D graphics, etc.). Analyzing further, the development process of visually augmented books will contribute favourably to their production and to provide real accessibility to the enduser. 
